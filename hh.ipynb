{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30545ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ingestion.database.reader import IngestionReaderInterface\n",
    "from src.ingestion.database.reader_psql import ConfigurePostgresSparkSession\n",
    "from src.ingestion.database.reader_psql import PostgresIngestionReader\n",
    "from pyspark.sql import SparkSession,Window\n",
    "from pyspark.sql.functions import from_json, col, schema_of_json, get_json_object\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from src.ingestion.database.reader import ReadContents\n",
    "from src.ingestion.database.reader import ReadUsers\n",
    "from src.ingestion.database.reader import ReadRatingFeedbacks\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c54c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b951ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_builder = SparkSession.builder.appName(\"Jupyter\")\n",
    "spark_builder = ConfigurePostgresSparkSession(spark_builder)\n",
    "spark = spark_builder.getOrCreate()\n",
    "reader = PostgresIngestionReader(db_host=\"127.0.0.1\", db_user=\"minfei\", db_password=\"FM199601060046gg\", spark=spark)\n",
    "content = ReadContents(reader)\n",
    "content.cache()\n",
    "user = ReadUsers(reader)\n",
    "rating = ReadRatingFeedbacks(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "748054f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/src/feature_processor/features_core/content_features.py\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "from pyspark.sql.functions import array_contains, col, explode\n",
    "from src.ingestion.database.reader import IngestionReaderInterface\n",
    "from src.ingestion.database.reader_psql import ConfigurePostgresSparkSession\n",
    "from src.ingestion.database.reader_psql import PostgresIngestionReader\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, get_json_object, expr, avg, count,broadcast\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from src.ingestion.database.reader import ReadContents\n",
    "from src.ingestion.database.reader import ReadUsers\n",
    "from src.ingestion.database.reader import ReadRatingFeedbacks\n",
    "from pyspark.sql.functions import array_contains, col, explode,  mean, stddev, substring,split,stddev_pop, avg, broadcast,regexp_replace\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler,StandardScaler\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector\n",
    "def VectorizeGenres(content_genres: DataFrame) -> DataFrame:\n",
    "    \"\"\"Encodes a list of genre strings into a multi-hot vector (a list of\n",
    "    floats).\n",
    "\n",
    "    Example input:\n",
    "    ---------------------------\n",
    "    | id | genres             |\n",
    "    ---------------------------\n",
    "    |  1 | [\"Action\", \"IMAX\"] |\n",
    "    ---------------------------\n",
    "\n",
    "    Example output:\n",
    "    ---------------------------\n",
    "    | id | genres             |\n",
    "    ---------------------------\n",
    "    |  1 | [0,1,...,0,1,0]    |\n",
    "    ---------------------------\n",
    "\n",
    "    Args:\n",
    "        content_genres (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    df1 = content_genres.select('id','genres')\n",
    "    # df1.first()['genres'] ##2 7 8\n",
    "    genres_list = [x[0] for x in df1.select(explode(\"genres\").alias(\"genres\")).distinct().orderBy(\"genres\").collect()]\n",
    "    df_sep = df1.select(\"*\" ,*[\n",
    "        array_contains(\"genres\", g).alias(\"g_{}\".format(g)).cast(\"integer\")\n",
    "        for g in genres_list]\n",
    "    ).drop('genres')\n",
    "    selected_columns = [column for column in df_sep.columns if column.startswith(\"g_\")] \n",
    "    assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_genres')\n",
    "    df_sep = assembler.transform(df_sep).select('id','sparse_genres')\n",
    "    def sparse_to_array(v):\n",
    "        v = DenseVector(v)\n",
    "        new_array = list([float(x) for x in v])\n",
    "        return new_array\n",
    "    sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "    res = df_sep.withColumn('genres', sparse_to_array_udf('sparse_genres')).select('id','genres')\n",
    "    return res\n",
    "\n",
    "def GetSpokenLanguages(content: DataFrame) -> DataFrame:\n",
    "    \"\"\"Extract list of languages strings from the column 'tmdb_primary_info', which is json object, \n",
    "        under 'spoken_languages' key\n",
    "\n",
    "     Example input:\n",
    "    -------------------------------\n",
    "    | id | tmdb_primary_info      |\n",
    "    -------------------------------\n",
    "    |  1 | '{\"id\": 399168, \"adult\": false, \"title\": \"The Mathematician and the Devil\", \"video\":\n",
    "             false, \"budget\": 0, \"genres\": [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"name\": \"Drama\"}, \n",
    "             {\"id\": 14, \"name\": \"Fantasy\"}], \"status\": \"Released\", \"imdb_id\": \"tt3154916\", \"revenue\": 0, \"runtime\": 21, \"tagline\": \"\", \"homepage\": \"\", \n",
    "             \"overview\": \"A mathematician offers to sell his soul to the devil for a proof or disproof of Fermat\\'s Last Theorem. Based on \\\\\"The Devil and Simon Flagg\\\\\" by Arthur Porges.\", \"popularity\": 0.6, \n",
    "             \"vote_count\": 6, \"poster_path\": \"/5JCaWtCySRPy2JbHwgUAmYJBM8b.jpg\", \"release_date\": \"1972-06-06\", \"vote_average\": 8.3,\n",
    "             \"backdrop_path\": null, \"original_title\": \"Математик и чёрт\", \n",
    "             \"spoken_languages\": [{\"name\": \"Pусский\", \"iso_639_1\": \"ru\", \"english_name\": \"Russian\"}], \n",
    "             \"original_language\": \"ru\", \"production_companies\": [{\"id\": 88367, \"name\": \"Centrnauchfilm\", \n",
    "             \"logo_path\": \"/8BGGqyuaxijzhqzmrgdCINWbPhj.png\", \"origin_country\": \"SU\"}],\n",
    "            \"production_countries\": [{\"name\": \"Soviet Union\", \"iso_3166_1\": \"SU\"}], \"belongs_to_collection\": null}') |\n",
    "    -------------------------------\n",
    "\n",
    "        Example output:\n",
    "    -------------------------------\n",
    "    | id | languages              |\n",
    "    -------------------------------\n",
    "    |  1 | [\"English\", \"Spanish\"] |\n",
    "    -------------------------------\n",
    "    \"\"\"\n",
    "    tmdb = content.select([\"id\",\"tmdb_primary_info\"])\n",
    "    lan = tmdb.withColumn('languages',get_json_object('tmdb_primary_info', '$.spoken_languages'))\n",
    "    newdf= lan.withColumn('spoken_languages_all', F.from_json(\n",
    "            F.col('languages'),\n",
    "            T.ArrayType(T.StructType([\n",
    "                T.StructField('name', T.StringType()),\n",
    "                T.StructField('iso_639_1', T.StringType()),\n",
    "                T.StructField('english_name', T.StringType()),\n",
    "            ]))\n",
    "        ))\n",
    "    newdf = newdf.select('id','spoken_languages_all')\n",
    "    spoken_languages = newdf.withColumn('languages' , expr(\"transform(spoken_languages_all, x -> x['english_name'])\"))\n",
    "    return spoken_languages.select('id','languages')\n",
    "\n",
    "def VectorizeLanguages(spoken_languages: DataFrame) -> DataFrame:\n",
    "    \"\"\"Encodes a list of language strings into a multi-hot vector (a list of\n",
    "    floats).\n",
    "\n",
    "    Example input: (take input from GetSpokenLanguages)\n",
    "    -------------------------------\n",
    "    | id | languages              |\n",
    "    -------------------------------\n",
    "    |  1 | [\"English\", \"Spanish\"] |\n",
    "    -------------------------------\n",
    "\n",
    "    Example output:\n",
    "    ---------------------------\n",
    "    | id | languages          |\n",
    "    ---------------------------\n",
    "    |  1 | [0,1,...,0,1,0]    |\n",
    "    ---------------------------\n",
    "\n",
    "    Args:\n",
    "        content_languages (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    df1 = spoken_languages.select('id','languages')\n",
    "    languages_list = [x[0] for x in df1.select(explode(\"languages\").alias(\"languages\")).distinct().orderBy(\"languages\").collect()]\n",
    "    df_sep = df1.select(\"*\" ,*[\n",
    "        array_contains(\"languages\", lan).alias(\"l_{}\".format(lan)).cast(\"integer\")\n",
    "        for lan in languages_list]\n",
    "    ).drop('languages')\n",
    "    selected_columns = [column for column in df_sep.columns if column.startswith(\"l_\")] \n",
    "    assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_languages',handleInvalid=\"skip\")\n",
    "    df_sep1 = assembler.transform(df_sep).select('id','sparse_languages').na.fill(value = 0, subset=[\"sparse_languages\"])\n",
    "    def sparse_to_array(v):\n",
    "        v = DenseVector(v)\n",
    "        new_array = list([float(x) for x in v])\n",
    "        return new_array\n",
    "    sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "    res = df_sep1.withColumn('languages', sparse_to_array_udf('sparse_languages')).select('id','languages')\n",
    "    return res\n",
    "def ComputeNormalizedAverageRating(\n",
    "        user_rating_feebacks: DataFrame) -> DataFrame:\n",
    "    \"\"\"Computes the average rating each piece of content receives. Then it\n",
    "    applies the following transformation to the average ratings:\n",
    "        normalized_avg_ratings =\n",
    "            (avg_ratings[content_id] - mean(avg_ratings))/std(avg_ratings)\n",
    "\n",
    "    Example input:\n",
    "    ------------------------\n",
    "    | content_id | rating  |\n",
    "    ------------------------\n",
    "    |  1         |  3      |\n",
    "    ------------------------\n",
    "    |  1         |  5      |\n",
    "    ------------------------\n",
    "    |  2         |  3      |\n",
    "    ------------------------\n",
    "    |  3         |  2      |\n",
    "    ------------------------\n",
    "    |  3         |  2      |\n",
    "    ------------------------\n",
    "\n",
    "    Average ratings (intermediate result):\n",
    "    ---------------------------\n",
    "    | content_id | avg_rating |\n",
    "    ---------------------------\n",
    "    |  1         |  4         |\n",
    "    ---------------------------\n",
    "    |  2         |  3         |\n",
    "    ---------------------------\n",
    "    |  3         |  2         |\n",
    "    ---------------------------\n",
    "    mean = 3, std = sqrt(2/3)\n",
    "\n",
    "    Example output:\n",
    "    -------------------\n",
    "    | id | avg_rating |\n",
    "    -------------------\n",
    "    |  1 |  1.2247    |\n",
    "    -------------------\n",
    "    |  2 |  0         |\n",
    "    -------------------\n",
    "    |  3 | -1.2247    |\n",
    "    -------------------\n",
    "\n",
    "    Args:\n",
    "        user_rating_feebacks (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    \n",
    "    content_rating = user_rating_feebacks.select('content_id', 'rating')\n",
    "    content_rating = content_rating.groupBy('content_id').agg(avg(\"rating\").alias(\"avg_rating_unscaled\"))\n",
    "    summary = content_rating.select([mean('avg_rating_unscaled').alias('mu'), stddev('avg_rating_unscaled').alias('sigma')]).collect().pop()\n",
    "    dft = content_rating.withColumn('avg_rating', (content_rating['avg_rating_unscaled']-summary.mu)/summary.sigma).select(col(\"content_id\").alias(\"id\"), 'avg_rating')\n",
    "    return dft\n",
    "def ComputeNormalizedRatingCount(\n",
    "        user_rating_feebacks: DataFrame) -> DataFrame:\n",
    "    \"\"\"Computes the number of ratings each piece of content receives. Then it\n",
    "    applies the following transformation to the counts:\n",
    "        normalized_count =\n",
    "            (rating_count[content_id] - mean(rating_counts))/std(rating_counts)\n",
    "\n",
    "    Example input:\n",
    "    ------------------------\n",
    "    | content_id | rating  |\n",
    "    ------------------------\n",
    "    |  1         |  3      |\n",
    "    ------------------------\n",
    "    |  1         |  5      |\n",
    "    ------------------------\n",
    "    |  2         |  3      |\n",
    "    ------------------------\n",
    "    |  3         |  2      |\n",
    "    ------------------------\n",
    "    |  3         |  2      |\n",
    "    ------------------------\n",
    "    |  3         |  1      |\n",
    "    ------------------------\n",
    "\n",
    "    Rating count (intermediate result):\n",
    "    -----------------------------\n",
    "    | content_id | rating_count |\n",
    "    -----------------------------\n",
    "    |  1         |  2           |\n",
    "    -----------------------------\n",
    "    |  2         |  1           |\n",
    "    -----------------------------\n",
    "    |  3         |  3           |\n",
    "    -----------------------------\n",
    "    mean = 2, std = sqrt(2/3)\n",
    "\n",
    "    Example output:\n",
    "    ---------------------\n",
    "    | id | rating_count |\n",
    "    ---------------------\n",
    "    |  1 |  0           |\n",
    "    ---------------------\n",
    "    |  2 | -1.2247      |\n",
    "    ---------------------\n",
    "    |  3 |  1.2247      |\n",
    "    ---------------------\n",
    "\n",
    "    Args:\n",
    "        user_rating_feebacks (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    \n",
    "    content_rating = user_rating_feebacks.select('content_id', 'rating')\n",
    "    content_rating = content_rating.groupBy('content_id').agg(count(\"*\").alias(\"count_unscaled\"))\n",
    "    summary = content_rating.select([mean('count_unscaled').alias('mu'), stddev('count_unscaled').alias('sigma')]).collect().pop()\n",
    "    rating_count_scaled = content_rating.withColumn('rating_count', (content_rating['count_unscaled']-summary.mu)/summary.sigma).select(col('content_id').alias('id'), 'rating_count')\n",
    "    return rating_count_scaled\n",
    "\n",
    "def GetBuget(content: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Extract budget from tmdb json column\n",
    "    \"\"\"\n",
    "    content_budget = content.withColumn('budget_unscaled',\n",
    "                   get_json_object('tmdb_primary_info', '$.budget')).select('id','budget_unscaled')\n",
    "    \n",
    "    return content_budget #some values are null\n",
    "def NormalizeBudget(content_budget: DataFrame) -> DataFrame:\n",
    "    \"\"\"Transforms all budgets, so they distribute in a unit normal.\n",
    "\n",
    "    Example input:\n",
    "    -------------------\n",
    "    | id | budget_unscaled |\n",
    "    -------------------\n",
    "    |  1 |  1,000,000 |\n",
    "    -------------------\n",
    "    |  3 |  3,000,000 |\n",
    "    -------------------\n",
    "    mean = 2,000,000, std = 1,000,000\n",
    "\n",
    "    Example output:\n",
    "    ---------------\n",
    "    | id | budget |\n",
    "    ---------------\n",
    "    |  1 |  -1    |\n",
    "    ---------------\n",
    "    |  3 |   1    |\n",
    "    ---------------\n",
    "\n",
    "    Args:\n",
    "        content_budget (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    budget_non0 = content_budget.filter(content_budget['budget_unscaled'] > 0) #null/0 budgets are left unprocessed\n",
    "    summary = budget_non0.select([mean('budget_unscaled').alias('mu'), stddev('budget_unscaled').alias('sigma')]).collect().pop()\n",
    "    budget_scaled = budget_non0.withColumn('budget', (budget_non0['budget_unscaled']-summary.mu)/summary.sigma).select('id', 'budget')\n",
    "    res = content_budget.join(budget_scaled, ['id'], 'leftouter').select('id','budget')\n",
    "    return res\n",
    "def GetRuntime(content: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Extract runtime from tmdb json column\n",
    "    \"\"\"\n",
    "    content_runtime = content.withColumn('runtime_unscaled',get_json_object('tmdb_primary_info', '$.runtime')).select('id','runtime_unscaled')\n",
    "    return content_runtime\n",
    "def NormalizeRuntime(content_runtime: DataFrame) -> DataFrame:\n",
    "    \"\"\"Transforms all runtimes, so they distribute in a unit normal.\n",
    "\n",
    "    Example input:\n",
    "    -------------------\n",
    "    | id | runtime_unscaled    |\n",
    "    -------------------\n",
    "    |  1 |  115       |\n",
    "    -------------------\n",
    "    |  3 |  75        |\n",
    "    -------------------\n",
    "    mean = 95, std = 1,000,000\n",
    "\n",
    "    Example output:\n",
    "    ----------------\n",
    "    | id | runtime |\n",
    "    ----------------\n",
    "    |  1 |   1     |\n",
    "    ----------------\n",
    "    |  3 |  -1     |\n",
    "    ----------------\n",
    "\n",
    "    Args:\n",
    "        content_runtime (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    runtime_non0 = content_runtime.filter(content_runtime['runtime_unscaled'] > 0) #null/0 runtime are left unprocessed\n",
    "    summary = runtime_non0.select([mean('runtime_unscaled').alias('mu'), stddev('runtime_unscaled').alias('sigma')]).collect().pop()\n",
    "    runtime_scaled = runtime_non0.withColumn('runtime', (runtime_non0['runtime_unscaled']-summary.mu)/summary.sigma).select('id', 'runtime')\n",
    "    res = content_runtime.join(runtime_scaled, ['id'], 'leftouter').select('id','runtime')\n",
    "    return res\n",
    "\n",
    "def GetReleaseYear(content: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Extract release year from tmdb json column\n",
    "    \"\"\"\n",
    "    tmdb = content.select([\"id\",\"tmdb_primary_info\"])\n",
    "    content_release_year = tmdb.withColumn('release_date',\n",
    "                   get_json_object('tmdb_primary_info', '$.release_date')).select('id','release_date')\n",
    "    content_release_year = content_release_year.select('id', substring('release_date', 1,4).alias('release_year_str'))\n",
    "    content_release_year= content_release_year.withColumn(\"release_year_unscaled\", content_release_year[\"release_year_str\"].cast(T.IntegerType())).select('id', 'release_year_unscaled')\n",
    "    return content_release_year\n",
    "\n",
    "def NormalizeReleaseYear(content_release_year: DataFrame) -> DataFrame:\n",
    "    \"\"\"Transform all the release years, so they distribute in a unit normal.\n",
    "\n",
    "    Example input:\n",
    "    ---------------------\n",
    "    | id | release_year |\n",
    "    ---------------------\n",
    "    |  1 |  1980        |\n",
    "    ---------------------\n",
    "    |  2 |  2002        |\n",
    "    ---------------------\n",
    "    |  3 |  2012        |\n",
    "    ---------------------\n",
    "    mean = 1998, std = 178.67\n",
    "\n",
    "    Example output:\n",
    "    ---------------------\n",
    "    | id | release_year |\n",
    "    ---------------------\n",
    "    |  1 |  -0.1        |\n",
    "    ---------------------\n",
    "    |  2 |   0.02       |\n",
    "    ---------------------\n",
    "    |  3 |   0.08       |\n",
    "    ---------------------\n",
    "\n",
    "    Args:\n",
    "        content_release_year (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "   \n",
    "    content_release_year_nonNull = content_release_year.filter(content_release_year['release_year_unscaled'].isNotNull()) #null/0 budgets are left unprocessed\n",
    "    summary = content_release_year_nonNull.select([mean('release_year_unscaled').alias('mu'), stddev('release_year_unscaled').alias('sigma')]).collect().pop()\n",
    "    release_year_scaled = content_release_year_nonNull.withColumn('release_year', (content_release_year_nonNull['release_year_unscaled']-summary.mu)/summary.sigma).select('id', 'release_year')\n",
    "    res = content_release_year.join(release_year_scaled, ['id'], 'leftouter').select('id','release_year')\n",
    "    return res\n",
    "\n",
    "def ComputeCasts(content: DataFrame) -> DataFrame:\n",
    "    '''\n",
    "     It first computes\n",
    "#     the absolute count for the number of people in each department under 'Casts', then it\n",
    "#     normalizes the count based on the mean and the standard deviation.\n",
    "\n",
    "    Intermidiate result:\n",
    "|    id|   |Acting|Actors|Art|Camera|Costume & Make-Up|Creator|Crew|Directing|Editing|Lighting|Production|Sound|Visual Effects|Writing|\n",
    "+------+---+------+------+---+------+-----------------+-------+----+---------+-------+--------+----------+-----+--------------+-------+\n",
    "| 97216|  0|    54|     0|  0|     0|                0|      0|   1|        0|      0|       0|         0|    0|             0|      0|\n",
    "| 71936|  0|    47|     0|  0|     0|                0|      0|   0|        0|      0|       0|         1|    0|             0|      0|\n",
    "| 62526|  0|    22|     0|  0|     0|                0|      0|   0|        0|      0|       0|         0|    0|             0|      0|\n",
    "\n",
    "#     Example output:\n",
    "#      ------------------------------------------------\n",
    "#     | id | cast_composition | crew_composition      |\n",
    "#     -------------------------------------------------\n",
    "#     | 1  | [1.0, 0.0, ...]  | [0.0, ..., -1.0, ...] |\n",
    "#     -------------------------------------------------\n",
    "#     | 2  | [-1.0, 0.0, ...] | [0.0, ..., 1.0, ...]  |\n",
    "#     -------------------------------------------------\n",
    "    '''\n",
    "    casts= content.withColumn('cast',\n",
    "                    get_json_object('tmdb_credits', '$.cast')).select('id','cast')\n",
    "    casts = casts.filter(casts['cast'].isNotNull()).withColumn('departments', F.udf(lambda x: [i['known_for_department'] for i in json.loads(x)]) ('cast')).select('id', 'departments')\n",
    "    casts2= casts.withColumn(\n",
    "        \"department\",\n",
    "        split(regexp_replace(col(\"departments\"), r\"(^\\[)|(\\]$)|(')\", \"\"), \", \")\n",
    "    )\n",
    "    casts2 = casts2.select('id', 'department')\n",
    "    casts2 = casts2.selectExpr(\"id\",\"explode(department) as department\").groupby(\"id\").pivot('department').count().na.fill(0)\n",
    "    # casts2:  Intermidiate result\n",
    "    # Normalize each column\n",
    "    selected_columns = [column for column in casts2.columns if column!='id' and column != '' ] \n",
    "    stats = (casts2.groupBy().agg(\n",
    "            *([stddev_pop(x).alias(x + '_stddev') for x in selected_columns] + \n",
    "            [avg(x).alias(x + '_avg') for x in selected_columns])))\n",
    "    df2 = casts2.join(broadcast(stats))\n",
    "    exprs = ['id']+[((df2[x] - df2[x + '_avg']) / df2[x + '_stddev']).alias(x) for x in selected_columns]\n",
    "    df2=df2.select(exprs)\n",
    "    #combine multiple columns into one feature:\n",
    "    assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_casts',handleInvalid=\"skip\")\n",
    "    df_sep1 = assembler.transform(df2).select('id','sparse_casts').na.fill(value = 0, subset=[\"sparse_casts\"])\n",
    "    #convert sparse array to dense array\n",
    "    def sparse_to_array(v):\n",
    "            v = DenseVector(v)\n",
    "            new_array = list([float(x) for x in v])\n",
    "            return new_array\n",
    "    sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "    res = df_sep1.withColumn('cast_composition', sparse_to_array_udf('sparse_casts')).select('id','cast_composition')\n",
    "    return res\n",
    "\n",
    "\n",
    "def ComputeCrews(content:DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "         It first computes\n",
    "#     the absolute count for the number of people in each department under 'crew', then it\n",
    "#     normalizes the count based on the mean and the standard deviation.\n",
    "\n",
    "    \"\"\"\n",
    "    crews= content.withColumn('crew',\n",
    "                    get_json_object('tmdb_credits', '$.crew')).select('id','crew')\n",
    "    crews = crews.filter(crews['crew'].isNotNull()).withColumn('departments', F.udf(lambda x: [i['department'] for i in json.loads(x)]) ('crew')).select('id', 'departments')\n",
    "    crews2= crews.withColumn(\n",
    "        \"department\",\n",
    "        split(regexp_replace(col(\"departments\"), r\"(^\\[)|(\\]$)\", \"\"), \", \")\n",
    "    )\n",
    "    crews2 = crews2.select('id', 'department')\n",
    "    crews2 = crews2.selectExpr(\"id\",\"explode(department) as department\").groupby(\"id\").pivot('department').count().na.fill(0)\n",
    "    selected_columns = [column for column in crews2.columns if column!='id' and column != '' ] \n",
    "    stats = (crews2.groupBy().agg(\n",
    "            *([stddev_pop(x).alias(x + '_stddev') for x in selected_columns] + \n",
    "            [avg(x).alias(x + '_avg') for x in selected_columns])))\n",
    "    df2 = crews2.join(broadcast(stats))\n",
    "    exprs = ['id']+[((df2[x] - df2[x + '_avg']) / df2[x + '_stddev']).alias(x) for x in selected_columns]\n",
    "    df2=df2.select(exprs)\n",
    "    assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_crews',handleInvalid=\"skip\")\n",
    "    df_sep1 = assembler.transform(df2).select('id','sparse_crews').na.fill(value = 0, subset=[\"sparse_crews\"])\n",
    "    #convert sparse array to dense array\n",
    "    def sparse_to_array(v):\n",
    "            v = DenseVector(v)\n",
    "            new_array = list([float(x) for x in v])\n",
    "            return new_array\n",
    "    sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "    res = df_sep1.withColumn('crew_composition', sparse_to_array_udf('sparse_crews')).select('id','crew_composition')\n",
    "    return res\n",
    "# def ComputeTeamComposition(\n",
    "#         content_credits: DataFrame) -> DataFrame:\n",
    "#     \"\"\"Finds the composition of the content creation team. It first computes\n",
    "#     the absolute count for the number of people in each department, then it\n",
    "#     normalizes the count based on the mean and the standard deviation.\n",
    "\n",
    "#     Example input:\n",
    "#     --------------------------------------------------\n",
    "#     | id | tmdb_credits                              |\n",
    "#     --------------------------------------------------\n",
    "#     | 1  | '\"cast\": [                                |\n",
    "#     |    |  { \"known_for_department\": \"Acting\" },    |\n",
    "#     |    |  { \"known_for_department\": \"Acting\" }     |\n",
    "#     |    | ],                                        |\n",
    "#     |    | \"crew\": [                                 |\n",
    "#     |    |  { \"known_for_department\": \"Directing\" }, |\n",
    "#     |    |  { \"known_for_department\": \"Writing\" }    |\n",
    "#     |    | ]'                                        |\n",
    "#     --------------------------------------------------\n",
    "#     | 2  | '\"cast\": [                                |\n",
    "#     |    |  { \"known_for_department\": \"Acting\" }     |\n",
    "#     |    | ],                                        |\n",
    "#     |    | \"crew\": [                                 |\n",
    "#     |    |  { \"known_for_department\": \"Directing\" }, |\n",
    "#     |    |  { \"known_for_department\": \"Sound\" }      |\n",
    "#     |    | ]'                                        |\n",
    "#     --------------------------------------------------\n",
    "\n",
    "#     Intermediate result (count by department):\n",
    "#     -------------------------------------------\n",
    "#     | id | department          | cast | count |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Acting\"            | true | 2     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Directing\"         | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Writing\"           | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Production\"        | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Crew\"              | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Sound\"             | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Camera\"            | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Art\"               | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Costume & Make-Up\" | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Editing\"           | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Visual Effects\"    | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Lighting\"          | true | 0     |\n",
    "#     -------------------------------------------\n",
    "#     | 1  | \"Creator\"           | true | 0     |\n",
    "#     -------------------------------------------\n",
    "\n",
    "#     ... ...\n",
    "\n",
    "\n",
    "#     Example output:\n",
    "#      ------------------------------------------------\n",
    "#     | id | cast_composition | crew_composition      |\n",
    "#     -------------------------------------------------\n",
    "#     | 1  | [1.0, 0.0, ...]  | [0.0, ..., -1.0, ...] |\n",
    "#     -------------------------------------------------\n",
    "#     | 2  | [-1.0, 0.0, ...] | [0.0, ..., 1.0, ...]  |\n",
    "#     -------------------------------------------------\n",
    "\n",
    "#     Args:\n",
    "#         content_credits (DataFrame): See the example input above.\n",
    "\n",
    "#     Returns:\n",
    "#         DataFrame: See the example output above.\n",
    "#     \"\"\"\n",
    "#     content_credits.show()\n",
    "\n",
    "def GetVoteCount(content: DataFrame) -> DataFrame:\n",
    "    '''\n",
    "    Extract Tmdb Vote count from content tmdb json column.\n",
    "    '''\n",
    "    tmdb = content.select([\"id\",\"tmdb_primary_info\"])\n",
    "    content_tmdb_vote_count= tmdb.withColumn('vote_count_unscaled',\n",
    "                    get_json_object('tmdb_primary_info', '$.vote_count')).select('id','vote_count_unscaled')\n",
    "    return content_tmdb_vote_count\n",
    "\n",
    "def NormalizeTmdbVoteCount(content_tmdb_vote_count: DataFrame) -> DataFrame:\n",
    "    \"\"\"Transform all the TMDB vote counts, so they distribute in a unit normal.\n",
    "\n",
    "    Example input:\n",
    "    --------------------------\n",
    "    | id | tmdb_vote_count   |\n",
    "    --------------------------\n",
    "    |  1 |  3000             |\n",
    "    --------------------------\n",
    "    |  2 |  2000             |\n",
    "    --------------------------\n",
    "    |  3 |  1000             |\n",
    "    --------------------------\n",
    "    mean = 2000, std = 816.5\n",
    "\n",
    "    Example output:\n",
    "    ------------------------\n",
    "    | id | tmdb_vote_count |\n",
    "    ------------------------\n",
    "    |  1 |  1.2247         |\n",
    "    ------------------------\n",
    "    |  2 |  0              |\n",
    "    ------------------------\n",
    "    |  3 |  -1.2247        |\n",
    "    ------------------------\n",
    "\n",
    "    Args:\n",
    "        content_tmdb_vote_count (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    \n",
    "    content_tmdb_vote_count_nonNull = content_tmdb_vote_count.filter(content_tmdb_vote_count['vote_count_unscaled'].isNotNull()) #null vote count are left unprocessed\n",
    "    summary = content_tmdb_vote_count_nonNull.select([mean('vote_count_unscaled').alias('mu'), stddev('vote_count_unscaled').alias('sigma')]).collect().pop()\n",
    "    vote_count_scaled = content_tmdb_vote_count_nonNull.withColumn('tmdb_vote_count', (content_tmdb_vote_count_nonNull['vote_count_unscaled']-summary.mu)/summary.sigma).select('id', 'tmdb_vote_count')\n",
    "    res = content_tmdb_vote_count.join(vote_count_scaled, ['id'], 'leftouter').select('id','tmdb_vote_count')\n",
    "    return res\n",
    "def GetTmdbAverageRating(content: DataFrame) -> DataFrame:\n",
    "   \"\"\"\n",
    "   Extract tmdb average rating from content tmdb json volumn.\n",
    "   \"\"\"\n",
    "   content_tmdb_avg_rating= content.withColumn('tmdb_avg_rating_unscaled',\n",
    "                   get_json_object('tmdb_primary_info', '$.vote_average')).select('id','tmdb_avg_rating_unscaled')\n",
    "   return content_tmdb_avg_rating\n",
    "\n",
    "def NormalizeTmdbAverageRating(\n",
    "        content_tmdb_avg_rating: DataFrame) -> DataFrame:\n",
    "    \"\"\"Transform all the TMDB average ratings, so they distribute in a unit\n",
    "    normal.\n",
    "\n",
    "    Example input:\n",
    "    --------------------------\n",
    "    | id | tmdb_avg_rating   |\n",
    "    --------------------------\n",
    "    |  1 |  9.5              |\n",
    "    --------------------------\n",
    "    |  2 |  7                |\n",
    "    --------------------------\n",
    "    |  3 |  2                |\n",
    "    --------------------------\n",
    "    mean = 6.2, std = 3.5\n",
    "\n",
    "    Example output:\n",
    "    ------------------------\n",
    "    | id | tmdb_avg_rating |\n",
    "    ------------------------\n",
    "    |  1 |   0.94          |\n",
    "    ------------------------\n",
    "    |  2 |   0.23          |\n",
    "    ------------------------\n",
    "    |  3 |  -1.2           |\n",
    "    ------------------------\n",
    "\n",
    "    Args:\n",
    "        content_tmdb_avg_rating (DataFrame): See the example input above.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: See the example output above.\n",
    "    \"\"\"\n",
    "    tmdb_avg_rating_nonNull = content_tmdb_avg_rating.filter(content_tmdb_avg_rating['tmdb_avg_rating_unscaled'].isNotNull()) #null avg rating are left unprocessed\n",
    "    summary = tmdb_avg_rating_nonNull.select([mean('tmdb_avg_rating_unscaled').alias('mu'), stddev('tmdb_avg_rating_unscaled').alias('sigma')]).collect().pop()\n",
    "    tmdb_avg_rating_scaled = tmdb_avg_rating_nonNull.withColumn('tmdb_avg_rating', (tmdb_avg_rating_nonNull['tmdb_avg_rating_unscaled']-summary.mu)/summary.sigma).select('id', 'tmdb_avg_rating')\n",
    "    res = content_tmdb_avg_rating.join(tmdb_avg_rating_scaled, ['id'], 'leftouter').select('id','tmdb_avg_rating')\n",
    "    return res\n",
    "\n",
    "def ComputeCoreContentFeatures(contents: DataFrame,\n",
    "                               user_rating_feebacks: DataFrame) -> DataFrame:\n",
    "    \"\"\"Extracts core features from the content dataframe as well as from the\n",
    "    user rating feedbacks. See below for the list of core features.\n",
    "\n",
    "    Args:\n",
    "        contents (DataFrame): The content dataframe with the schema as follows,\n",
    "            root\n",
    "                |-- id: long (nullable = false)\n",
    "                |-- title: string (nullable = true)\n",
    "                |-- genres: array (nullable = true)\n",
    "                |    |-- element: string (containsNull = false)\n",
    "                |-- genome_scores: json (nullable = true)\n",
    "                |-- tags: json (nullable = true)\n",
    "                |-- imdb_id: integer (nullable = true)\n",
    "                |-- tmdb_id: integer (nullable = true)\n",
    "                |-- imdb_primary_info: json (nullable = true)\n",
    "                |-- tmdb_primary_info: json (nullable = true)\n",
    "                |-- tmdb_credits: json (nullable = true)\n",
    "        user_rating_feebacks (DataFrame): The user rating feedback dataframe\n",
    "            with the schema as follows:\n",
    "            root\n",
    "                |-- user_id: long (nullable = false)\n",
    "                |-- content_id: long (nullable = false)\n",
    "                |-- rated_at: timestamp (nullable = false)\n",
    "                |-- rating: double (nullable = false)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: A dataframe containing core content features, and the schema\n",
    "            goes as below,\n",
    "            root\n",
    "                |-- id: long (nullable = false)\n",
    "                |-- genres: array (nullable = false)\n",
    "                |    |-- element: float (containsNull = false)\n",
    "                |-- languages: array (nullable = false)\n",
    "                |    |-- element: float (containsNull = false)\n",
    "                |-- avg_rating: float (nullable = true)\n",
    "                |-- rating_count: float (nullable = true)\n",
    "                |-- budget: float (nullable = true)\n",
    "                |-- runtime: float (nullable = true)\n",
    "                |-- release_year: float (nullable = true)\n",
    "                |-- cast_composition: array (nullable = true)\n",
    "                |    |-- element: float (containsNull = false)\n",
    "                |-- crew_composition: array (nullable = true)\n",
    "                |    |-- element: float (containsNull = false)\n",
    "                |-- tmdb_avg_rating: float (nullable = true)\n",
    "                |-- tmdb_vote_count: float (nullable = true)\n",
    "    \"\"\"\n",
    "    \n",
    "    genres = VectorizeGenres(contents)\n",
    "    spoken_language = GetSpokenLanguages(contents)\n",
    "    languages = VectorizeLanguages(spoken_language)\n",
    "    avg_rating = ComputeNormalizedAverageRating(user_rating_feebacks)\n",
    "    rating_count = ComputeNormalizedRatingCount(user_rating_feebacks)\n",
    "    dollar_budget =GetBuget(contents)\n",
    "    budget = NormalizeBudget(dollar_budget)\n",
    "    unscaled_runtime = GetRuntime(contents)\n",
    "    runtime = NormalizeRuntime(unscaled_runtime)\n",
    "    release_year_unscaled = GetReleaseYear(contents)\n",
    "    release_year  = NormalizeReleaseYear(release_year_unscaled)\n",
    "    cast_composition = ComputeCasts(contents)\n",
    "    crew_composition = ComputeCrews(contents)\n",
    "    vote_count_unscaled = GetVoteCount(contents) \n",
    "    tmdb_vote_count = NormalizeTmdbVoteCount(vote_count_unscaled)\n",
    "    tmdb_avg_rating = GetTmdbAverageRating(contents)\n",
    "    tmdb_avg_rating = NormalizeTmdbAverageRating(tmdb_avg_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.join(languages, ['id'], 'outer').join(avg_rating, ['id'], 'outer').join(rating_count, ['id'], 'outer').take(1)\n",
    "    .join(budget, ['id'], 'outer').join(runtime,['id'], 'outer').join(release_year, ['id'], 'outer')\\\n",
    "        .join(cast_composition,['id'], 'outer' ).join(crew_composition,['id'], 'outer' ).join(tmdb_avg_rating,['id'], 'outer' )\\\n",
    "            .join(tmdb_avg_rating, ['id'], 'outer' ).join(tmdb_vote_count,  ['id'], 'outer' ).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2f94cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/01 22:37:28 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 59:>   (0 + 1) / 1][Stage 60:>   (0 + 1) / 1][Stage 61:>   (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/01 22:37:35 ERROR Executor: Exception in task 0.0 in stage 62.0 (TID 35)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3481)\n",
      "\tat java.base/java.util.ArrayList.grow(ArrayList.java:237)\n",
      "\tat java.base/java.util.ArrayList.grow(ArrayList.java:244)\n",
      "\tat java.base/java.util.ArrayList.add(ArrayList.java:454)\n",
      "\tat java.base/java.util.ArrayList.add(ArrayList.java:467)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2348)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:496)\n",
      "\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:413)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:190)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:134)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:314)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2769/0x00000008019a1640.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "22/12/01 22:37:35 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 0.0 in stage 62.0 (TID 35),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3481)\n",
      "\tat java.base/java.util.ArrayList.grow(ArrayList.java:237)\n",
      "\tat java.base/java.util.ArrayList.grow(ArrayList.java:244)\n",
      "\tat java.base/java.util.ArrayList.add(ArrayList.java:454)\n",
      "\tat java.base/java.util.ArrayList.add(ArrayList.java:467)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2348)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:496)\n",
      "\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:413)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:190)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:134)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:314)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2769/0x00000008019a1640.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "22/12/01 22:37:35 WARN TaskSetManager: Lost task 0.0 in stage 62.0 (TID 35) (mins-mbp.lan executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3481)\n",
      "\tat java.base/java.util.ArrayList.grow(ArrayList.java:237)\n",
      "\tat java.base/java.util.ArrayList.grow(ArrayList.java:244)\n",
      "\tat java.base/java.util.ArrayList.add(ArrayList.java:454)\n",
      "\tat java.base/java.util.ArrayList.add(ArrayList.java:467)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2348)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:356)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:496)\n",
      "\tat org.postgresql.jdbc.PgStatement.execute(PgStatement.java:413)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:190)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:134)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JDBCRDD.compute(JDBCRDD.scala:314)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:329)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:136)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:548)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner$$Lambda$2769/0x00000008019a1640.apply(Unknown Source)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:833)\n",
      "\n",
      "22/12/01 22:37:35 ERROR TaskSetManager: Task 0 in stage 62.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 51524)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/accumulators.py\", line 281, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/accumulators.py\", line 253, in poll\n",
      "    if func():\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/accumulators.py\", line 257, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n",
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3369, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_13727/2582549266.py\", line 1, in <cell line: 1>\n",
      "    genres.join(languages, ['id'], 'outer').join(avg_rating, ['id'], 'outer').join(rating_count, ['id'], 'outer').take(1)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\", line 868, in take\n",
      "    return self.limit(num).collect()\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\", line 817, in collect\n",
      "    sock_info = self._jdf.collectToPython()\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1321, in __call__\n",
      "    return_value = get_return_value(\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py\", line 190, in deco\n",
      "    return f(*a, **kw)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py\", line 326, in get_return_value\n",
      "    raise Py4JJavaError(\n",
      "py4j.protocol.Py4JJavaError: <unprintable Py4JJavaError object>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 516, in send_command\n",
      "    raise Py4JNetworkError(\"Answer from Java side is empty\")\n",
      "py4j.protocol.Py4JNetworkError: Answer from Java side is empty\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    },
    {
     "ename": "ConnectionRefusedError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y154sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m genres\u001b[39m.\u001b[39;49mjoin(languages, [\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39mouter\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mjoin(avg_rating, [\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39mouter\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mjoin(rating_count, [\u001b[39m'\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m'\u001b[39;49m], \u001b[39m'\u001b[39;49m\u001b[39mouter\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mtake(\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:868\u001b[0m, in \u001b[0;36mDataFrame.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[39m\"\"\"Returns the first ``num`` rows as a :class:`list` of :class:`Row`.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \n\u001b[1;32m    861\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[39m[Row(age=2, name='Alice'), Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m    867\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlimit(num)\u001b[39m.\u001b[39;49mcollect()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:817\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mwith\u001b[39;00m SCCallSiteSync(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sc):\n\u001b[0;32m--> 817\u001b[0m     sock_info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mcollectToPython()\n\u001b[1;32m    818\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(_load_from_socket(sock_info, BatchedSerializer(CPickleSerializer())))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    191\u001b[0m \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31m<class 'str'>\u001b[0m: (<class 'ConnectionRefusedError'>, ConnectionRefusedError(61, 'Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:1993\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1990\u001b[0m     traceback\u001b[39m.\u001b[39mprint_exc()\n\u001b[1;32m   1991\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1993\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_showtraceback(etype, value, stb)\n\u001b[1;32m   1994\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall_pdb:\n\u001b[1;32m   1995\u001b[0m     \u001b[39m# drop into debugger\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebugger(force\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ipykernel/zmqshell.py:542\u001b[0m, in \u001b[0;36mZMQInteractiveShell._showtraceback\u001b[0;34m(self, etype, evalue, stb)\u001b[0m\n\u001b[1;32m    536\u001b[0m sys\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    537\u001b[0m sys\u001b[39m.\u001b[39mstderr\u001b[39m.\u001b[39mflush()\n\u001b[1;32m    539\u001b[0m exc_content \u001b[39m=\u001b[39m {\n\u001b[1;32m    540\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtraceback\u001b[39m\u001b[39m'\u001b[39m : stb,\n\u001b[1;32m    541\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mename\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mstr\u001b[39m(etype\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m),\n\u001b[0;32m--> 542\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mevalue\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mstr\u001b[39;49m(evalue),\n\u001b[1;32m    543\u001b[0m }\n\u001b[1;32m    545\u001b[0m dh \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisplayhook\n\u001b[1;32m    546\u001b[0m \u001b[39m# Send exception info over pub socket for other clients than the caller\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[39m# to pick up\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/protocol.py:471\u001b[0m, in \u001b[0;36mPy4JJavaError.__str__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__str__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    470\u001b[0m     gateway_client \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_exception\u001b[39m.\u001b[39m_gateway_client\n\u001b[0;32m--> 471\u001b[0m     answer \u001b[39m=\u001b[39m gateway_client\u001b[39m.\u001b[39;49msend_command(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexception_cmd)\n\u001b[1;32m    472\u001b[0m     return_value \u001b[39m=\u001b[39m get_return_value(answer, gateway_client, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    473\u001b[0m     \u001b[39m# Note: technically this should return a bytestring 'str' rather than\u001b[39;00m\n\u001b[1;32m    474\u001b[0m     \u001b[39m# unicodes in Python 2; however, it can return unicodes for now.\u001b[39;00m\n\u001b[1;32m    475\u001b[0m     \u001b[39m# See https://github.com/bartdag/py4j/issues/306 for more details.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msend_command\u001b[39m(\u001b[39mself\u001b[39m, command, retry\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, binary\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m     \u001b[39m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[39m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[39m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[39m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_connection()\n\u001b[1;32m   1037\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m connection \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m connection\u001b[39m.\u001b[39msocket \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_new_connection()\n\u001b[1;32m    285\u001b[0m \u001b[39mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_create_new_connection\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[39m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_parameters, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_property, \u001b[39mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     connection\u001b[39m.\u001b[39;49mconnect_to_java_server()\n\u001b[1;32m    292\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py:438\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context:\n\u001b[1;32m    436\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mssl_context\u001b[39m.\u001b[39mwrap_socket(\n\u001b[1;32m    437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket, server_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjava_address)\n\u001b[0;32m--> 438\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msocket\u001b[39m.\u001b[39;49mconnect((\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_address, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjava_port))\n\u001b[1;32m    439\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket\u001b[39m.\u001b[39mmakefile(\u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_connected \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Exception while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/socket.py\", line 704, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [Errno 54] Connection reset by peer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/py4j/clientserver.py\", line 539, in send_command\n",
      "    raise Py4JNetworkError(\n",
      "py4j.protocol.Py4JNetworkError: Error while sending or receiving\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa250de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "genres = VectorizeGenres(content)\n",
    "spoken_language = GetSpokenLanguages(content)\n",
    "languages = VectorizeLanguages(spoken_language)\n",
    "avg_rating = ComputeNormalizedAverageRating(rating)\n",
    "rating_count = ComputeNormalizedRatingCount(rating)\n",
    "dollar_budget =GetBuget(content)\n",
    "budget = NormalizeBudget(dollar_budget)\n",
    "unscaled_runtime = GetRuntime(content)\n",
    "runtime = NormalizeRuntime(unscaled_runtime)\n",
    "release_year_unscaled = GetReleaseYear(content)\n",
    "release_year  = NormalizeReleaseYear(release_year_unscaled)\n",
    "cast_composition = ComputeCasts(content)\n",
    "crew_composition = ComputeCrews(content)\n",
    "vote_count_unscaled = GetVoteCount(content) \n",
    "tmdb_vote_count = NormalizeTmdbVoteCount(vote_count_unscaled)\n",
    "tmdb_avg_rating = GetTmdbAverageRating(content)\n",
    "tmdb_avg_rating = NormalizeTmdbAverageRating(tmdb_avg_rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e269278",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94591fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 155:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|     tmdb_avg_rating|\n",
      "+---+--------------------+\n",
      "|  1|   1.447818102074664|\n",
      "|  2|  0.9296197423481904|\n",
      "|  3| 0.36186689466973193|\n",
      "|  4|  0.2684212888174166|\n",
      "|  5|  0.2132034308137764|\n",
      "|  6|  1.4010952991485068|\n",
      "|  7| 0.16648062788761844|\n",
      "|  8| -0.4048118260731246|\n",
      "|  9|0.004366660158981151|\n",
      "| 10|  0.6733522475107813|\n",
      "| 11|  0.4701788469076421|\n",
      "| 12| 0.07374294329176094|\n",
      "| 13|  0.9706791752226923|\n",
      "| 14|  0.7115799953594557|\n",
      "| 15|-0.09686607951435985|\n",
      "| 16|  1.4789666373587689|\n",
      "| 17|  1.0931495525897414|\n",
      "| 18|-0.15845522882611268|\n",
      "| 19| 0.27479258012552926|\n",
      "| 20|-0.08553933941104895|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tmdb_avg_rating.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c9440b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|vote_count_unscaled|\n",
      "+---+-------------------+\n",
      "|  1|              15929|\n",
      "+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vote_count_unscaled.filter(col('id')==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698e26d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0ceab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddfeb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fd52a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|user_id|rating|\n",
      "+-------+------+\n",
      "|  79679|   2.0|\n",
      "|  79679|   4.0|\n",
      "|  79679|   4.0|\n",
      "|  79679|   4.0|\n",
      "|  79738|   1.0|\n",
      "|  79738|   4.0|\n",
      "|  79738|   1.0|\n",
      "|  79738|   1.0|\n",
      "|  79738|   1.0|\n",
      "|  79738|   1.0|\n",
      "+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_rating = rating.select('user_id', 'rating')\n",
    "content_rating.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "eec0093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 598:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+--------------------+\n",
      "|user_id|count_unscaled|        rating_count|\n",
      "+-------+--------------+--------------------+\n",
      "| 274182|           410|  1.4664842070632833|\n",
      "| 264195|           336|  1.1186756491278669|\n",
      "| 247112|           143|   0.211553329107118|\n",
      "| 274800|           316|  1.0246733361723488|\n",
      "|  10422|          1326|   5.771790140426008|\n",
      "|  15237|           599|  2.3548060644929283|\n",
      "|  11619|           649|   2.589811846881723|\n",
      "|   3764|            15| -0.3900614738081972|\n",
      "|  15663|             5| -0.4370626302859562|\n",
      "|  31762|            85|-0.06105337846388419|\n",
      "| 268933|           481|  1.8001924180553723|\n",
      "|  22429|           311|  1.0011727579334693|\n",
      "|  23766|            96|-0.00935210633834...|\n",
      "|  41862|           122| 0.11285090050382411|\n",
      "|  35323|           248|  0.7050654721235876|\n",
      "|  25207|            18| -0.3759611268648695|\n",
      "|  30428|           315|  1.0199732205245728|\n",
      "|  52743|           168|  0.3290562203015155|\n",
      "|  47928|            15| -0.3900614738081972|\n",
      "|  64873|           384|    1.34428120022111|\n",
      "+-------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "content_rating = rating.select('user_id', 'rating')\n",
    "content_rating = content_rating.groupBy('user_id').agg(count(\"*\").alias(\"count_unscaled\"))\n",
    "summary = content_rating.select([mean('count_unscaled').alias('mu'), stddev('count_unscaled').alias('sigma')]).collect().pop()\n",
    "dft = content_rating.withColumn('rating_count', (content_rating['count_unscaled']-summary.mu)/summary.sigma)\n",
    "dft.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "26cc9625",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Column 'rating' does not exist. Did you mean one of the following? [user_id, rating_unscaled];\n'Aggregate [avg('rating) AS mu#41376, stddev_samp('rating) AS sigma#41386]\n+- Aggregate [user_id#37L], [user_id#37L, count(1) AS rating_unscaled#41372L]\n   +- Project [user_id#37L, rating#40]\n      +- Project [user_id#37L, content_id#38L, rated_at#39, rating#40]\n         +- Relation [user_id#37L,content_id#38L,rated_at#39,rating#40,ingested_at#41] JDBCRelation(user_rating) [numPartitions=1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m content_rating \u001b[39m=\u001b[39m rating\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m content_rating \u001b[39m=\u001b[39m content_rating\u001b[39m.\u001b[39mgroupBy(\u001b[39m'\u001b[39m\u001b[39muser_id\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39magg(count(\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39malias(\u001b[39m\"\u001b[39m\u001b[39mrating_unscaled\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m summary \u001b[39m=\u001b[39m content_rating\u001b[39m.\u001b[39;49mselect([mean(\u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m'\u001b[39;49m\u001b[39mmu\u001b[39;49m\u001b[39m'\u001b[39;49m), stddev(\u001b[39m'\u001b[39;49m\u001b[39mrating\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49malias(\u001b[39m'\u001b[39;49m\u001b[39msigma\u001b[39;49m\u001b[39m'\u001b[39;49m)])\u001b[39m.\u001b[39mcollect()\u001b[39m.\u001b[39mpop()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#X33sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m dft \u001b[39m=\u001b[39m content_rating\u001b[39m.\u001b[39mwithColumn(\u001b[39m'\u001b[39m\u001b[39mavg_rating\u001b[39m\u001b[39m'\u001b[39m, (content_rating[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m-\u001b[39msummary\u001b[39m.\u001b[39mmu)\u001b[39m/\u001b[39msummary\u001b[39m.\u001b[39msigma)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#X33sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m dft\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2023\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   2002\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mcols: \u001b[39m\"\u001b[39m\u001b[39mColumnOrName\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mDataFrame\u001b[39m\u001b[39m\"\u001b[39m:  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m     \u001b[39m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \n\u001b[1;32m   2005\u001b[0m \u001b[39m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2021\u001b[0m \u001b[39m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2023\u001b[0m     jdf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jdf\u001b[39m.\u001b[39;49mselect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jcols(\u001b[39m*\u001b[39;49mcols))\n\u001b[1;32m   2024\u001b[0m     \u001b[39mreturn\u001b[39;00m DataFrame(jdf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Column 'rating' does not exist. Did you mean one of the following? [user_id, rating_unscaled];\n'Aggregate [avg('rating) AS mu#41376, stddev_samp('rating) AS sigma#41386]\n+- Aggregate [user_id#37L], [user_id#37L, count(1) AS rating_unscaled#41372L]\n   +- Project [user_id#37L, rating#40]\n      +- Project [user_id#37L, content_id#38L, rated_at#39, rating#40]\n         +- Relation [user_id#37L,content_id#38L,rated_at#39,rating#40,ingested_at#41] JDBCRelation(user_rating) [numPartitions=1]\n"
     ]
    }
   ],
   "source": [
    "# content_rating = rating.select('user_id', 'rating')\n",
    "# content_rating = content_rating.groupBy('user_id').agg(count('*').alias(\"rating_unscaled\"))\n",
    "# summary = content_rating.select([mean('rating').alias('mu'), stddev('rating').alias('sigma')]).collect().pop()\n",
    "# dft = content_rating.withColumn('avg_rating', (content_rating['rating']-summary.mu)/summary.sigma)\n",
    "# dft.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5c9e441f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, languages: array<string>]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the original_language of movies\n",
    "# tmdb = content.select([\"id\",\"tmdb_primary_info\"])\n",
    "# lan = tmdb.withColumn('orginal_language',\n",
    "#                    get_json_object('tmdb_primary_info', '$.original_language'))\n",
    "# lan.show(10)\n",
    "\n",
    "#get the original_language of movies\n",
    "tmdb = content.select([\"id\",\"tmdb_primary_info\"])\n",
    "lan = tmdb.withColumn('languages',\n",
    "                   get_json_object('tmdb_primary_info', '$.spoken_languages'))\n",
    "newdf= lan.withColumn('spoken_languages_all', F.from_json(\n",
    "        F.col('languages'),\n",
    "        T.ArrayType(T.StructType([\n",
    "            T.StructField('name', T.StringType()),\n",
    "            T.StructField('iso_639_1', T.StringType()),\n",
    "            T.StructField('english_name', T.StringType()),\n",
    "        ]))\n",
    "    ))\n",
    "newdf = newdf.select('id','spoken_languages_all')\n",
    "spoken_languages = newdf.withColumn('languages' , expr(\"transform(spoken_languages_all, x -> x['english_name'])\"))\n",
    "spoken_languages.select('id','languages')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a36190f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df1 = spoken_languages.select('id','languages')\n",
    "\n",
    "df1 = spoken_languages.select('id','languages')\n",
    "languages_list = [x[0] for x in df1.select(explode(\"languages\").alias(\"languages\")).distinct().orderBy(\"languages\").collect()]\n",
    "df_sep = df1.select(\"*\" ,*[\n",
    "    array_contains(\"languages\", lan).alias(\"l_{}\".format(lan)).cast(\"integer\")\n",
    "    for lan in languages_list]\n",
    ").drop('languages')\n",
    "selected_columns = [column for column in df_sep.columns if column.startswith(\"l_\")] \n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_languages',handleInvalid=\"skip\")\n",
    "\n",
    "df_sep1 = assembler.transform(df_sep).select('id','sparse_languages').na.fill(value = 0, subset=[\"sparse_languages\"])\n",
    "\n",
    "df_sep1.take(20)\n",
    "def sparse_to_array(v):\n",
    "    v = DenseVector(v)\n",
    "    new_array = list([float(x) for x in v])\n",
    "    return new_array\n",
    "sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "res = df_sep1.withColumn('languages', sparse_to_array_udf('sparse_languages')).select('id','languages')\n",
    "#res.filter(res['id'] ==  147752) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e91962f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|    id|budget_unscaled|\n",
      "+------+---------------+\n",
      "|191689|              0|\n",
      "|147752|              0|\n",
      "|154984|              0|\n",
      "|132725|              0|\n",
      "|164819|           null|\n",
      "|174751|              0|\n",
      "|158094|           null|\n",
      "|127419|              0|\n",
      "|136824|              0|\n",
      "| 25989|              0|\n",
      "|156027|              0|\n",
      "|160325|              0|\n",
      "|  2477|              0|\n",
      "|186437|              0|\n",
      "| 65986|              0|\n",
      "|140355|              0|\n",
      "|167570|           null|\n",
      "|109736|              0|\n",
      "|174903|              0|\n",
      "|167044|              0|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "budget.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a42b431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|    id|vote_count_unscaled|\n",
      "+------+-------------------+\n",
      "|191689|                  6|\n",
      "|147752|                  6|\n",
      "|154984|                 22|\n",
      "|132725|                  0|\n",
      "|164819|               null|\n",
      "|174751|                  9|\n",
      "|158094|               null|\n",
      "|127419|                 46|\n",
      "|136824|                  6|\n",
      "| 25989|                 62|\n",
      "|156027|                 67|\n",
      "|160325|                 10|\n",
      "|  2477|                133|\n",
      "|186437|                 26|\n",
      "| 65986|                 12|\n",
      "|140355|                 11|\n",
      "|167570|               null|\n",
      "|109736|                  6|\n",
      "|174903|                  1|\n",
      "|167044|                  1|\n",
      "+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_tmdb_vote_count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bceab0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 127:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|    id|tmdb_vote_count|\n",
      "+------+---------------+\n",
      "|164819|            0.0|\n",
      "+------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tmdb = content.select([\"id\",\"tmdb_primary_info\"])\n",
    "content_tmdb_vote_count= tmdb.withColumn('vote_count_unscaled',\n",
    "                   get_json_object('tmdb_primary_info', '$.vote_count')).select('id','vote_count_unscaled')\n",
    "\n",
    "\n",
    "content_tmdb_vote_count_nonNull = content_tmdb_vote_count.filter(content_tmdb_vote_count['vote_count_unscaled'].isNotNull()) #null vote count are left unprocessed\n",
    "\n",
    "summary = content_tmdb_vote_count_nonNull.select([mean('vote_count_unscaled').alias('mu'), stddev('vote_count_unscaled').alias('sigma')]).collect().pop()\n",
    "vote_count_scaled = content_tmdb_vote_count_nonNull.withColumn('tmdb_vote_count', (content_tmdb_vote_count_nonNull['vote_count_unscaled']-summary.mu)/summary.sigma).select('id', 'tmdb_vote_count')\n",
    "res = content_tmdb_vote_count.join(vote_count_scaled, ['id'], 'leftouter').na.fill(value = 0, subset=[\"tmdb_vote_count\"]).select('id','tmdb_vote_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "66122202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|              budget|\n",
      "+------+--------------------+\n",
      "|177479| -0.5733302404941284|\n",
      "|177081| -0.5742063429599672|\n",
      "|102517| -0.5773316507706047|\n",
      "|153961|-0.48346715899808546|\n",
      "| 69873| 0.14325899781449788|\n",
      "|138300| -0.3895990376582078|\n",
      "|178637| -0.5757708116489652|\n",
      "|  1188|-0.48346715899808546|\n",
      "| 47525| -0.5084986580220529|\n",
      "|   505|   0.674239670860406|\n",
      "|120274|  -0.420888411438167|\n",
      "| 49007|-0.42714628619415884|\n",
      "| 81094|-0.45217778521812624|\n",
      "|176751|  0.9871334086599983|\n",
      "|  4148|  2.1448402385184897|\n",
      "|  4578|-0.07670529985861549|\n",
      "|  4967| -0.5456656467984561|\n",
      "| 71239| -0.3676964760122363|\n",
      "| 77818| -0.2644415425383709|\n",
      "|187577|  0.5177928019606098|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmdb = content.select([\"id\",\"tmdb_primary_info\"])\n",
    "budget = tmdb.withColumn('budget_unscaled',\n",
    "                   get_json_object('tmdb_primary_info', '$.budget')).select('id','budget_unscaled')\n",
    "budget_non0 = budget.filter(budget['budget_unscaled'] > 0)\n",
    "summary = budget_non0.select([mean('budget_unscaled').alias('mu'), stddev('budget_unscaled').alias('sigma')]).collect().pop()\n",
    "budget_scaled = budget_non0.withColumn('budget', (budget_non0['budget_unscaled']-summary.mu)/summary.sigma).select('id', 'budget')\n",
    "res = budget.join(budget_scaled, ['id'], 'leftouter').na.fill(value = 0, subset=[\"budget\"]).select('id','budget')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "feecd172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------------+\n",
      "|    id|release_year_unscaled|\n",
      "+------+---------------------+\n",
      "|191689|                 1972|\n",
      "|147752|                 2014|\n",
      "|154984|                 1967|\n",
      "|132725|                 1963|\n",
      "|164819|                 null|\n",
      "|174751|                 2017|\n",
      "|158094|                 null|\n",
      "|127419|                 2013|\n",
      "|136824|                 2002|\n",
      "| 25989|                 1955|\n",
      "|156027|                 2012|\n",
      "|160325|                 2011|\n",
      "|  2477|                 1986|\n",
      "|186437|                 1942|\n",
      "| 65986|                 1950|\n",
      "|140355|                 2013|\n",
      "|167570|                 null|\n",
      "|109736|                 2012|\n",
      "|174903|                 2002|\n",
      "|167044|                 2014|\n",
      "+------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_release_year = tmdb.withColumn('release_date',\n",
    "                   get_json_object('tmdb_primary_info', '$.release_date')).select('id','release_date')\n",
    "content_release_year = content_release_year.select('id', substring('release_date', 1,4).alias('release_year_str'))\n",
    "content_release_year= content_release_year.withColumn(\"release_year_unscaled\", content_release_year[\"release_year_str\"].cast(T.IntegerType())).select('id', 'release_year_unscaled')\n",
    "\n",
    "content_release_year.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3eddf60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=191689, tmdb_primary_info='{\"id\": 399168, \"adult\": false, \"title\": \"The Mathematician and the Devil\", \"video\": false, \"budget\": 0, \"genres\": [{\"id\": 35, \"name\": \"Comedy\"}, {\"id\": 18, \"name\": \"Drama\"}, {\"id\": 14, \"name\": \"Fantasy\"}], \"status\": \"Released\", \"imdb_id\": \"tt3154916\", \"revenue\": 0, \"runtime\": 21, \"tagline\": \"\", \"homepage\": \"\", \"overview\": \"A mathematician offers to sell his soul to the devil for a proof or disproof of Fermat\\'s Last Theorem. Based on \\\\\"The Devil and Simon Flagg\\\\\" by Arthur Porges.\", \"popularity\": 0.6, \"vote_count\": 6, \"poster_path\": \"/5JCaWtCySRPy2JbHwgUAmYJBM8b.jpg\", \"release_date\": \"1972-06-06\", \"vote_average\": 8.3, \"backdrop_path\": null, \"original_title\": \"Математик и чёрт\", \"spoken_languages\": [{\"name\": \"Pусский\", \"iso_639_1\": \"ru\", \"english_name\": \"Russian\"}], \"original_language\": \"ru\", \"production_companies\": [{\"id\": 88367, \"name\": \"Centrnauchfilm\", \"logo_path\": \"/8BGGqyuaxijzhqzmrgdCINWbPhj.png\", \"origin_country\": \"SU\"}], \"production_countries\": [{\"name\": \"Soviet Union\", \"iso_3166_1\": \"SU\"}], \"belongs_to_collection\": null}')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmdb.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67104426",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|        release_year|\n",
      "+------+--------------------+\n",
      "|  2453| -0.2137536585794371|\n",
      "|154986| -0.8532724309610892|\n",
      "|148347| -1.7326107429858608|\n",
      "|124609| -2.3321595920936598|\n",
      "| 88228| -1.5327611266165944|\n",
      "| 96734|-0.09384388875787733|\n",
      "| 32954| -0.5335130447702631|\n",
      "|121997| -2.0124002059028334|\n",
      "|133907| -0.5335130447702631|\n",
      "| 91056| -1.6926408197120075|\n",
      "|  3764|-0.01390404221017...|\n",
      "| 89881|  -1.612700973164301|\n",
      "|183799| -0.7733325844133826|\n",
      "|126753| -0.9332122775087957|\n",
      "| 62526| -0.6534228145918228|\n",
      "|169522|-0.17378373530558383|\n",
      "| 63676| -1.0131521240565022|\n",
      "|128283|  -1.612700973164301|\n",
      "|161736| -0.8532724309610892|\n",
      "| 89806| -1.5327611266165944|\n",
      "| 79035| -2.0124002059028334|\n",
      "|  2250|-0.05387396548402...|\n",
      "|  7279| -0.6534228145918228|\n",
      "|122045| -1.8125505895335672|\n",
      "|104498| -0.7733325844133826|\n",
      "|  6721|-0.01390404221017...|\n",
      "|190709| -0.9332122775087957|\n",
      "|124703| -1.6526708964381542|\n",
      "| 40436| -1.6926408197120075|\n",
      "|  4894| -0.3736333516748501|\n",
      "| 81085|-0.17378373530558383|\n",
      "| 48899|  -1.612700973164301|\n",
      "|176843|-0.09384388875787733|\n",
      "|174339| -3.2514678273922843|\n",
      "|181933| -1.7326107429858608|\n",
      "|115084|  -2.412099438641366|\n",
      "| 33760| -1.8125505895335672|\n",
      "|174215| -3.2914377506661374|\n",
      "|188057| -0.5734829680441164|\n",
      "| 71936|  -1.452821280068888|\n",
      "|116185| -2.2921896688198062|\n",
      "|119585| -1.2529716636996218|\n",
      "| 93816| -1.1330618938780619|\n",
      "|123425| -2.1722798989982466|\n",
      "| 86791| -1.4128513567950347|\n",
      "| 26486|-0.33366342840099683|\n",
      "| 58509| -2.0124002059028334|\n",
      "|188319| -1.6926408197120075|\n",
      "|  4590|-0.09384388875787733|\n",
      "|129986| -0.9731822007826489|\n",
      "|128784| -0.9731822007826489|\n",
      "|173355|-0.33366342840099683|\n",
      "|  2529| -0.9332122775087957|\n",
      "|104854| -1.0531220473303555|\n",
      "|  5385| -0.5335130447702631|\n",
      "|167440| -0.3736333516748501|\n",
      "|137634| -0.4935431214964099|\n",
      "| 49754|-0.33366342840099683|\n",
      "|122613| -0.9332122775087957|\n",
      "|  8484|  -1.292941586973475|\n",
      "|153955| -1.0131521240565022|\n",
      "|173791| -1.4128513567950347|\n",
      "|125171| -1.3728814335211814|\n",
      "|111343|-0.05387396548402...|\n",
      "|118448| -2.2921896688198062|\n",
      "|160894| -0.8532724309610892|\n",
      "| 86453| -1.0531220473303555|\n",
      "|   964| -1.7725806662597139|\n",
      "|128245| -0.3736333516748501|\n",
      "| 88576| -0.8133025076872359|\n",
      "|172035|  -1.292941586973475|\n",
      "|133107| -0.8133025076872359|\n",
      "|169990| -0.7333626611395294|\n",
      "|176741|  -3.331407673939991|\n",
      "|112603| -0.8133025076872359|\n",
      "|173289| -1.5727310498904477|\n",
      "|151813|-0.33366342840099683|\n",
      "|152419| -1.3329115102473281|\n",
      "|190877|-0.01390404221017...|\n",
      "|157951|-0.05387396548402...|\n",
      "|  3091| -0.4535731982225566|\n",
      "|153094| -0.8932423542349424|\n",
      "|157324| -0.8532724309610892|\n",
      "| 59861| -2.2921896688198062|\n",
      "|  2040| -0.8932423542349424|\n",
      "|  2927| -1.8525205128074205|\n",
      "| 55671| -2.0124002059028334|\n",
      "|134532| -0.9332122775087957|\n",
      "|163997| -2.4920392851890725|\n",
      "| 88133| -1.3329115102473281|\n",
      "|129421| -1.5327611266165944|\n",
      "|135061|-0.05387396548402...|\n",
      "|153306|-0.01390404221017...|\n",
      "|147907| -1.8525205128074205|\n",
      "|158445| -1.6526708964381542|\n",
      "| 31156|  -1.612700973164301|\n",
      "|136275|-0.33366342840099683|\n",
      "|126150| -0.6933927378656761|\n",
      "|  1950| -0.9731822007826489|\n",
      "|154224| -1.1730318171519152|\n",
      "|161554|  -2.252219745545953|\n",
      "|  3506| -0.4935431214964099|\n",
      "| 69299|  -2.412099438641366|\n",
      "|118528| -0.5734829680441164|\n",
      "|  7225| -0.5734829680441164|\n",
      "|161468| -0.4935431214964099|\n",
      "|152541|  -2.252219745545953|\n",
      "|  2214|  -2.372129515367513|\n",
      "|133904|   -2.09234005245054|\n",
      "|149272|  -1.932460359355127|\n",
      "| 25826| -2.2122498222720997|\n",
      "| 89041| -0.6933927378656761|\n",
      "| 26140| -1.0131521240565022|\n",
      "|160744| -0.9731822007826489|\n",
      "| 79578| -0.5734829680441164|\n",
      "|  3106|-0.05387396548402...|\n",
      "|  5934| -0.3736333516748501|\n",
      "|128019| -1.9724302826289803|\n",
      "|174067| -0.8133025076872359|\n",
      "| 98304|  -2.372129515367513|\n",
      "|131757|-0.17378373530558383|\n",
      "|125515|  -2.132309975724393|\n",
      "|  1010| -0.9332122775087957|\n",
      "|180523|-0.01390404221017...|\n",
      "| 73256| -0.1338138120317306|\n",
      "|  3015| -0.5335130447702631|\n",
      "|  1258| -0.4535731982225566|\n",
      "|  2895| -0.7733325844133826|\n",
      "|  3391|-0.17378373530558383|\n",
      "|185897|-0.05387396548402...|\n",
      "|  8092|-0.05387396548402...|\n",
      "| 82051|  -2.412099438641366|\n",
      "| 26389| -0.5335130447702631|\n",
      "|125283| -2.4520693619152194|\n",
      "|124091| -0.4935431214964099|\n",
      "|160247| -2.4520693619152194|\n",
      "|151173|   -2.09234005245054|\n",
      "|134011|  -2.571979131736779|\n",
      "| 31598|-0.01390404221017...|\n",
      "| 81443| -2.3321595920936598|\n",
      "| 77896| -0.6933927378656761|\n",
      "|131286| -0.6933927378656761|\n",
      "|  1224|-0.09384388875787733|\n",
      "|155221| -0.8133025076872359|\n",
      "| 25999| -1.5327611266165944|\n",
      "| 81102| -1.0930919706042086|\n",
      "|171073| -0.6534228145918228|\n",
      "|124255|  -1.452821280068888|\n",
      "|190469|-0.33366342840099683|\n",
      "|140455|-0.33366342840099683|\n",
      "|113549| -0.8932423542349424|\n",
      "|163320|  -2.252219745545953|\n",
      "| 79711|  -2.412099438641366|\n",
      "|116811| -1.0930919706042086|\n",
      "|  1360| -0.3736333516748501|\n",
      "|159678| -1.0531220473303555|\n",
      "|  4126|-0.17378373530558383|\n",
      "|188137|-0.33366342840099683|\n",
      "|123854|  -2.252219745545953|\n",
      "|192549| -0.6134528913179697|\n",
      "|118302|-0.33366342840099683|\n",
      "|177065| -0.4935431214964099|\n",
      "|142119|   -2.09234005245054|\n",
      "|123028| -1.9724302826289803|\n",
      "| 31545| -1.2529716636996218|\n",
      "|142685| -0.6134528913179697|\n",
      "|123806| -1.9724302826289803|\n",
      "| 25946| -1.7326107429858608|\n",
      "|121963| -2.1722798989982466|\n",
      "|142987|  -2.851768594653752|\n",
      "|  3806| -0.8932423542349424|\n",
      "|175237|-0.05387396548402...|\n",
      "|187677| -1.8525205128074205|\n",
      "|  5759| -0.3736333516748501|\n",
      "|  7130| -1.0531220473303555|\n",
      "|  1277|-0.05387396548402...|\n",
      "|  2173| -0.1338138120317306|\n",
      "|182073|   -2.09234005245054|\n",
      "|182141|  -2.372129515367513|\n",
      "|152121| -0.8133025076872359|\n",
      "|  6424|-0.01390404221017...|\n",
      "|167938| -0.2137536585794371|\n",
      "|  3199| -1.3728814335211814|\n",
      "|131644| -0.4935431214964099|\n",
      "|153851| -0.7733325844133826|\n",
      "| 96060| -0.4935431214964099|\n",
      "|158240|  -1.452821280068888|\n",
      "| 54239| -2.4520693619152194|\n",
      "|163370| -1.6526708964381542|\n",
      "|174671| -0.7333626611395294|\n",
      "|187131|  -1.292941586973475|\n",
      "|  3061| -1.9724302826289803|\n",
      "| 84508| -1.4927912033427413|\n",
      "|135524| -0.2137536585794371|\n",
      "|124500| -1.8125505895335672|\n",
      "|  3280| -0.7333626611395294|\n",
      "| 76085| -0.8532724309610892|\n",
      "|167444|-0.17378373530558383|\n",
      "| 39786| -1.2529716636996218|\n",
      "|171667| -0.9731822007826489|\n",
      "| 97685|  -1.932460359355127|\n",
      "|122677| -0.8932423542349424|\n",
      "|   541| -0.3736333516748501|\n",
      "|123971|  -2.252219745545953|\n",
      "|145326| -1.8924904360812738|\n",
      "| 99515|  -1.292941586973475|\n",
      "|118995| -0.9332122775087957|\n",
      "|171307| -0.6134528913179697|\n",
      "|  5241| -0.4535731982225566|\n",
      "|152852| -0.3736333516748501|\n",
      "|120272|-0.33366342840099683|\n",
      "|158990| -1.6526708964381542|\n",
      "| 83034|  -1.612700973164301|\n",
      "|  6401| -0.8532724309610892|\n",
      "| 64953| -0.1338138120317306|\n",
      "|  2941| -1.3329115102473281|\n",
      "|113798| -1.8924904360812738|\n",
      "| 71386| -1.4128513567950347|\n",
      "|138933| -0.6933927378656761|\n",
      "| 72910|-0.17378373530558383|\n",
      "| 46457| -1.0131521240565022|\n",
      "| 88979|-0.33366342840099683|\n",
      "|127673| -1.2529716636996218|\n",
      "| 92348| -0.8932423542349424|\n",
      "| 87238|-0.01390404221017...|\n",
      "|161882| -0.3736333516748501|\n",
      "|163725| -1.0531220473303555|\n",
      "|138130| -0.6933927378656761|\n",
      "|190983|-0.41360327494870336|\n",
      "|133990|-0.33366342840099683|\n",
      "|141006|-0.33366342840099683|\n",
      "|135232| -0.5734829680441164|\n",
      "|116104| -0.7733325844133826|\n",
      "| 95182|-0.05387396548402...|\n",
      "| 98171|  -2.611949055010632|\n",
      "|  3741| -0.7333626611395294|\n",
      "|106996| -1.3329115102473281|\n",
      "|120785| -1.9724302826289803|\n",
      "|  4551| -0.1338138120317306|\n",
      "|  7121| -1.6926408197120075|\n",
      "| 82129| -1.6926408197120075|\n",
      "|158262| -0.9731822007826489|\n",
      "|  1127|-0.09384388875787733|\n",
      "|  6856| -1.9724302826289803|\n",
      "|147657|-0.41360327494870336|\n",
      "| 59838| -0.7733325844133826|\n",
      "| 25966| -1.5727310498904477|\n",
      "|130692| -0.8932423542349424|\n",
      "|141474| -0.9731822007826489|\n",
      "| 64959|  -1.932460359355127|\n",
      "|156303| -1.4927912033427413|\n",
      "|162938|-0.09384388875787733|\n",
      "|172587| -0.4535731982225566|\n",
      "|121648|  -2.252219745545953|\n",
      "|  2989|-0.41360327494870336|\n",
      "|129268| -0.2936935051271436|\n",
      "|157365| -1.4128513567950347|\n",
      "|156696| -0.6134528913179697|\n",
      "|  1371| -0.4935431214964099|\n",
      "|118274| -0.2137536585794371|\n",
      "|106351| -1.3329115102473281|\n",
      "|124263|  -1.292941586973475|\n",
      "| 78465| -1.6526708964381542|\n",
      "| 97526| -1.6526708964381542|\n",
      "|119305|-0.05387396548402...|\n",
      "|146204| -0.8932423542349424|\n",
      "|114457| -0.8133025076872359|\n",
      "|146760| -1.0930919706042086|\n",
      "|120594|  -1.292941586973475|\n",
      "|160392|-0.33366342840099683|\n",
      "|146018| -0.6534228145918228|\n",
      "|  7847|-0.25372358185329036|\n",
      "|162934|-0.33366342840099683|\n",
      "|143749| -0.8932423542349424|\n",
      "|177087| -0.9731822007826489|\n",
      "|160229| -0.1338138120317306|\n",
      "|174917| -3.8909865997739366|\n",
      "|130237|-0.17378373530558383|\n",
      "|106462| -1.5327611266165944|\n",
      "| 25759|  -2.532009208462926|\n",
      "|184625|  -2.891738517927605|\n",
      "|159968|-0.41360327494870336|\n",
      "|156278|  -2.132309975724393|\n",
      "|146868| -0.8532724309610892|\n",
      "|   938| -1.3329115102473281|\n",
      "|  2184|  -1.452821280068888|\n",
      "|114431| -1.2130017404257685|\n",
      "| 74382| -2.1722798989982466|\n",
      "| 95746| -0.4935431214964099|\n",
      "|  5148| -1.0930919706042086|\n",
      "| 84183|-0.41360327494870336|\n",
      "|  3704|-0.25372358185329036|\n",
      "| 80014| -0.9332122775087957|\n",
      "|154711| -1.8924904360812738|\n",
      "| 63793| -1.6526708964381542|\n",
      "|140080|-0.25372358185329036|\n",
      "|147180| -0.2936935051271436|\n",
      "|174201| -3.4113475204876975|\n",
      "|  3937| -0.2936935051271436|\n",
      "|  2517|-0.33366342840099683|\n",
      "+------+--------------------+\n",
      "only showing top 300 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_release_year = tmdb.withColumn('release_date',\n",
    "                   get_json_object('tmdb_primary_info', '$.release_date')).select('id','release_date')\n",
    "content_release_year = content_release_year.select('id', substring('release_date', 1,4).alias('release_year_str'))\n",
    "content_release_year= content_release_year.withColumn(\"release_year_unscaled\", content_release_year[\"release_year_str\"].cast(T.IntegerType())).select('id', 'release_year_unscaled')\n",
    "\n",
    "\n",
    "content_release_year_nonNull = content_release_year.filter(content_release_year['release_year_unscaled'].isNotNull()) #null/0 budgets are left unprocessed\n",
    "#content_release_year_nonNull.show()\n",
    "summary = content_release_year_nonNull.select([mean('release_year_unscaled').alias('mu'), stddev('release_year_unscaled').alias('sigma')]).collect().pop()\n",
    "release_year_scaled = content_release_year_nonNull.withColumn('release_year', (content_release_year_nonNull['release_year_unscaled']-summary.mu)/summary.sigma).select('id', 'release_year')\n",
    "res = content_release_year.join(release_year_scaled, ['id'], 'leftouter').na.fill(value = 0, subset=[\"release_year\"]).select('id','release_year')\n",
    "# return res\n",
    "res.filter(res['release_year'] < 0).show(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2821e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmdb = content.select([\"id\",\"tmdb_primary_info\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceac252f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 49:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "| id|             runtime|\n",
      "+---+--------------------+\n",
      "|  1|-0.47434215919753714|\n",
      "|  2|   0.308206248751211|\n",
      "|  3| 0.20613471727963517|\n",
      "|  4|   1.090754656699959|\n",
      "|  5| 0.37625393639892823|\n",
      "|  6|  2.5537799411258795|\n",
      "|  7|   1.090754656699959|\n",
      "|  8|  0.0700393419842007|\n",
      "|  9| 0.37625393639892823|\n",
      "| 10|   1.192826188171535|\n",
      "| 11|  0.6484446869897972|\n",
      "| 12|-0.23617525243052684|\n",
      "| 13|  -0.576413690669113|\n",
      "| 14|   3.302304505250769|\n",
      "| 15|  0.9886831252283833|\n",
      "| 16|   2.859994535540607|\n",
      "| 17|  1.3969692511146867|\n",
      "| 18| 0.10406318580805932|\n",
      "| 19| -0.1681275647828096|\n",
      "| 20|  0.5123493116943627|\n",
      "+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_runtime= content.withColumn('runtime_unscaled',\n",
    "                   get_json_object('tmdb_primary_info', '$.runtime')).select('id','runtime_unscaled')\n",
    "runtime_non0 = content_runtime.filter(content_runtime['runtime_unscaled'] > 0) #null/0 runtime are left unprocessed\n",
    "summary = runtime_non0.select([mean('runtime_unscaled').alias('mu'), stddev('runtime_unscaled').alias('sigma')]).collect().pop()\n",
    "runtime_scaled = runtime_non0.withColumn('runtime', (runtime_non0['runtime_unscaled']-summary.mu)/summary.sigma).select('id', 'runtime')\n",
    "res = content_runtime.join(runtime_scaled, ['id'], 'leftouter').na.fill(value = 0, subset=[\"runtime\"]).select('id','runtime')\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8126e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9519be04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tag': 'Bridget Terry', 'timestamp_secs': 1422435184}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(df.select(['tags']).take(1)[0][\"tags\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f15d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = content_genres.select('id','cont')\n",
    "genres_list = [x[0] for x in df1.select(explode(\"genres\").alias(\"genres\")).distinct().orderBy(\"genres\").collect()]\n",
    "df_sep = df1.select(\"*\", *[\n",
    "    array_contains(\"genres\", g).alias(\"g_{}\".format(g)).cast(\"integer\")\n",
    "    for g in genres_list]\n",
    "    ).drop('genres')\n",
    "selected_columns = [column for column in df_sep.columns if column.startswith(\"g_\")] \n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_genres')\n",
    "df_sep = assembler.transform(df_sep).select('id','sparse_genres')\n",
    "def sparse_to_array(v):\n",
    "    v = DenseVector(v)\n",
    "    new_array = list([float(x) for x in v])\n",
    "    return new_array\n",
    "\n",
    "sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "res = df_sep.withColumn('genres', sparse_to_array_udf('sparse_genres')).select('id','genres')\n",
    "return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad1b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------+\n",
      "|    id|tmdb_avg_rating_unscaled|\n",
      "+------+------------------------+\n",
      "|191689|                     8.3|\n",
      "|147752|                     3.8|\n",
      "|154984|                     5.5|\n",
      "|132725|                     0.0|\n",
      "|164819|                    null|\n",
      "|174751|                     4.7|\n",
      "|158094|                    null|\n",
      "|127419|                   4.772|\n",
      "|136824|                     7.8|\n",
      "| 25989|                    7.21|\n",
      "|156027|                     5.8|\n",
      "|160325|                     5.5|\n",
      "|  2477|                   5.308|\n",
      "|186437|                     7.0|\n",
      "| 65986|                     5.6|\n",
      "|140355|                     6.9|\n",
      "|167570|                    null|\n",
      "|109736|                     8.7|\n",
      "|174903|                     8.0|\n",
      "|167044|                     6.5|\n",
      "+------+------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "content_tmdb_avg_rating.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa980856",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------------+\n",
      "|    id|tmdb_avg_rating|\n",
      "+------+---------------+\n",
      "|103478|           null|\n",
      "|157965|           null|\n",
      "|163076|           null|\n",
      "|192339|           null|\n",
      "|112844|           null|\n",
      "|115895|           null|\n",
      "|176883|           null|\n",
      "|182481|           null|\n",
      "|   730|           null|\n",
      "|101483|           null|\n",
      "|106074|           null|\n",
      "|141739|           null|\n",
      "|150548|           null|\n",
      "|158545|           null|\n",
      "|176777|           null|\n",
      "|104119|           null|\n",
      "|109381|           null|\n",
      "|166225|           null|\n",
      "|166735|           null|\n",
      "| 69201|           null|\n",
      "+------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "content_tmdb_avg_rating= content.withColumn('tmdb_avg_rating_unscaled',\n",
    "                   get_json_object('tmdb_primary_info', '$.vote_average')).select('id','tmdb_avg_rating_unscaled')\n",
    "\n",
    "tmdb_avg_rating_nonNull = content_tmdb_avg_rating.filter(content_tmdb_avg_rating['tmdb_avg_rating_unscaled'].isNotNull()) #null avg rating are left unprocessed\n",
    "\n",
    "summary = tmdb_avg_rating_nonNull.select([mean('tmdb_avg_rating_unscaled').alias('mu'), stddev('tmdb_avg_rating_unscaled').alias('sigma')]).collect().pop()\n",
    "tmdb_avg_rating_scaled = tmdb_avg_rating_nonNull.withColumn('tmdb_avg_rating', (tmdb_avg_rating_nonNull['tmdb_avg_rating_unscaled']-summary.mu)/summary.sigma).select('id', 'tmdb_avg_rating')\n",
    "res = content_tmdb_avg_rating.join(tmdb_avg_rating_scaled, ['id'], 'leftouter').select('id','tmdb_avg_rating')\n",
    "\n",
    "res.filter(res['tmdb_avg_rating'].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45fb7a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 1625694,\n",
       "  'job': 'Story',\n",
       "  'name': 'Arthur Porges',\n",
       "  'adult': False,\n",
       "  'gender': 0,\n",
       "  'credit_id': '57458af992514129a0002537',\n",
       "  'department': 'Writing',\n",
       "  'popularity': 0.6,\n",
       "  'profile_path': None,\n",
       "  'original_name': 'Arthur Porges',\n",
       "  'known_for_department': 'Writing'},\n",
       " {'id': 1786440,\n",
       "  'job': 'Screenplay',\n",
       "  'name': 'Semyon Raytburt',\n",
       "  'adult': False,\n",
       "  'gender': 2,\n",
       "  'credit_id': '5b5f2df1c3a3684221056faa',\n",
       "  'department': 'Writing',\n",
       "  'popularity': 1.4,\n",
       "  'profile_path': None,\n",
       "  'original_name': 'Semyon Raytburt',\n",
       "  'known_for_department': 'Directing'},\n",
       " {'id': 1786440,\n",
       "  'job': 'Director',\n",
       "  'name': 'Semyon Raytburt',\n",
       "  'adult': False,\n",
       "  'gender': 2,\n",
       "  'credit_id': '5b5f2e04c3a368421e054d1a',\n",
       "  'department': 'Directing',\n",
       "  'popularity': 1.4,\n",
       "  'profile_path': None,\n",
       "  'original_name': 'Semyon Raytburt',\n",
       "  'known_for_department': 'Directing'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(content.first()['tmdb_credits'])['crew']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55443e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Row(id=191689, crew='[{\"id\":1625694,\"job\":\"Story\",\"name\":\"Arthur Porges\",\"adult\":false,\"gender\":0,\"credit_id\":\"57458af992514129a0002537\",\"department\":\"Writing\",\"popularity\":0.6,\"profile_path\":null,\"original_name\":\"Arthur Porges\",\"known_for_department\":\"Writing\"},{\"id\":1786440,\"job\":\"Screenplay\",\"name\":\"Semyon Raytburt\",\"adult\":false,\"gender\":2,\"credit_id\":\"5b5f2df1c3a3684221056faa\",\"department\":\"Writing\",\"popularity\":1.4,\"profile_path\":null,\"original_name\":\"Semyon Raytburt\",\"known_for_department\":\"Directing\"},{\"id\":1786440,\"job\":\"Director\",\"name\":\"Semyon Raytburt\",\"adult\":false,\"gender\":2,\"credit_id\":\"5b5f2e04c3a368421e054d1a\",\"department\":\"Directing\",\"popularity\":1.4,\"profile_path\":null,\"original_name\":\"Semyon Raytburt\",\"known_for_department\":\"Directing\"}]')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_tmdb_avg_rating= content.withColumn('crew',\n",
    "                   get_json_object('tmdb_credits', '$.crew')).select('id','crew')\n",
    "content_tmdb_avg_rating.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7244f82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1625692,\n",
       "  'name': 'Vsevolod Shestakov',\n",
       "  'adult': False,\n",
       "  'order': 0,\n",
       "  'gender': 0,\n",
       "  'cast_id': 0,\n",
       "  'character': 'Математик',\n",
       "  'credit_id': '57458a9c925141656200049c',\n",
       "  'popularity': 0.6,\n",
       "  'profile_path': '/sRiXFDtxrLnkYCXM235ywLjTbhm.jpg',\n",
       "  'original_name': 'Vsevolod Shestakov',\n",
       "  'known_for_department': 'Acting'},\n",
       " {'id': 28078,\n",
       "  'name': 'Aleksandr Kaydanovskiy',\n",
       "  'adult': False,\n",
       "  'order': 1,\n",
       "  'gender': 2,\n",
       "  'cast_id': 1,\n",
       "  'character': 'Черт',\n",
       "  'credit_id': '57458aab92514165940004a4',\n",
       "  'popularity': 2.883,\n",
       "  'profile_path': '/yHYfkxQu3GVKxx5ibFmEom8qAS6.jpg',\n",
       "  'original_name': 'Aleksandr Kaydanovskiy',\n",
       "  'known_for_department': 'Acting'},\n",
       " {'id': 587911,\n",
       "  'name': 'Alla Pokrovskaya',\n",
       "  'adult': False,\n",
       "  'order': 2,\n",
       "  'gender': 1,\n",
       "  'cast_id': 7,\n",
       "  'character': '',\n",
       "  'credit_id': '5b5f340f0e0a262e8d04fea5',\n",
       "  'popularity': 0.753,\n",
       "  'profile_path': '/flaYwCHvSzYhzm0bGFwyxhq6stS.jpg',\n",
       "  'original_name': 'Alla Pokrovskaya',\n",
       "  'known_for_department': 'Acting'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e19a8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8bd2249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Apple': 1, 'Pear': 1, 'Peach': 1, 'Banana': 1})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fruits = [\"Apple\", \"Pear\", \"Peach\", \"Banana\"]\n",
    "\n",
    "Counter(fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8c66197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Acting', 'Acting', 'Acting']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j1 = json.loads(content_tmdb_avg_rating.first()['cast'])\n",
    "\n",
    "[i['known_for_department'] for i in json.loads(content_tmdb_avg_rating.first()['cast'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "casts= content.withColumn('cast',\n",
    "            get_json_object('tmdb_credits', '$.cast')).select('id','cast')\n",
    "casts = casts.filter(casts['cast'].isNotNull()).withColumn('departments', F.udf(lambda x: [i['known_for_department'] for i in json.loads(x)]) ('cast')).select('id', 'departments')\n",
    "casts2= casts.withColumn(\n",
    "\"department\",\n",
    "split(regexp_replace(col(\"departments\"), r\"(^\\[)|(\\]$)|(')\", \"\"), \", \")\n",
    ")\n",
    "casts2 = casts2.select('id', 'department')\n",
    "casts2 = casts2.selectExpr(\"id\",\"explode(department) as department\").groupby(\"id\").pivot('department').count().na.fill(0)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "374fa69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=191689, crew='[{\"id\":1625694,\"job\":\"Story\",\"name\":\"Arthur Porges\",\"adult\":false,\"gender\":0,\"credit_id\":\"57458af992514129a0002537\",\"department\":\"Writing\",\"popularity\":0.6,\"profile_path\":null,\"original_name\":\"Arthur Porges\",\"known_for_department\":\"Writing\"},{\"id\":1786440,\"job\":\"Screenplay\",\"name\":\"Semyon Raytburt\",\"adult\":false,\"gender\":2,\"credit_id\":\"5b5f2df1c3a3684221056faa\",\"department\":\"Writing\",\"popularity\":1.4,\"profile_path\":null,\"original_name\":\"Semyon Raytburt\",\"known_for_department\":\"Directing\"},{\"id\":1786440,\"job\":\"Director\",\"name\":\"Semyon Raytburt\",\"adult\":false,\"gender\":2,\"credit_id\":\"5b5f2e04c3a368421e054d1a\",\"department\":\"Directing\",\"popularity\":1.4,\"profile_path\":null,\"original_name\":\"Semyon Raytburt\",\"known_for_department\":\"Directing\"}]')]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.withColumn('crew',\n",
    "                    get_json_object('tmdb_credits', '$.crew')).select('id','crew').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "62e668d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "crews= content.withColumn('crew',\n",
    "                    get_json_object('tmdb_credits', '$.crew')).select('id','crew')\n",
    "crews = crews.filter(crews['crew'].isNotNull()).withColumn('departments', F.udf(lambda x: [i['department'] for i in json.loads(x)]) ('crew')).select('id', 'departments')\n",
    "crews2= crews.withColumn(\n",
    "    \"department\",\n",
    "    split(regexp_replace(col(\"departments\"), r\"(^\\[)|(\\]$)\", \"\"), \", \")\n",
    ")\n",
    "crews2 = crews2.select('id', 'department')\n",
    "crews2 = crews2.selectExpr(\"id\",\"explode(department) as department\").groupby(\"id\").pivot('department').count().na.fill(0)\n",
    "selected_columns = [column for column in crews2.columns if column!='id' and column != '' ] \n",
    "stats = (crews2.groupBy().agg(\n",
    "        *([stddev_pop(x).alias(x + '_stddev') for x in selected_columns] + \n",
    "        [avg(x).alias(x + '_avg') for x in selected_columns])))\n",
    "df2 = crews2.join(broadcast(stats))\n",
    "exprs = ['id']+[((df2[x] - df2[x + '_avg']) / df2[x + '_stddev']).alias(x) for x in selected_columns]\n",
    "df2=df2.select(exprs)\n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_crews',handleInvalid=\"skip\")\n",
    "df_sep1 = assembler.transform(df2).select('id','sparse_crews').na.fill(value = 0, subset=[\"sparse_crews\"])\n",
    "#convert sparse array to dense array\n",
    "def sparse_to_array(v):\n",
    "        v = DenseVector(v)\n",
    "        new_array = list([float(x) for x in v])\n",
    "        return new_array\n",
    "sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "res = df_sep1.withColumn('crew_composition', sparse_to_array_udf('sparse_crews')).select('id','crew_composition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "db1ee3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(id=63676, sparse_crews=DenseVector([-0.0114, 0.4717, -0.1972, -0.1719, -0.2302, -0.4518, -0.0909, -0.1964, -0.152, -0.1449, -0.1408, -0.002]))]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sep1.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9782eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "eecea3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 391:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/01 21:32:55 ERROR Executor: Exception in task 0.0 in stage 391.0 (TID 245)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <lambda>\n",
      "  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <listcomp>\n",
      "KeyError: 'known_for_department'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "22/12/01 21:32:55 WARN TaskSetManager: Lost task 0.0 in stage 391.0 (TID 245) (mins-mbp.lan executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <lambda>\n",
      "  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <listcomp>\n",
      "KeyError: 'known_for_department'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:559)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:86)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:68)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:512)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:491)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
      "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
      "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n",
      "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:438)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:272)\n",
      "\n",
      "22/12/01 21:32:55 ERROR TaskSetManager: Task 0 in stage 391.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 187, in manager\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 730, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/Users/minfei/opt/anaconda3/lib/python3.9/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <lambda>\n  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <listcomp>\nKeyError: 'known_for_department'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m casts2\u001b[39m=\u001b[39m casts\u001b[39m.\u001b[39mwithColumn(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdepartment\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     split(regexp_replace(col(\u001b[39m\"\u001b[39m\u001b[39mdepartments\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(^\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[)|(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m]$)|(\u001b[39m\u001b[39m'\u001b[39m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m casts2 \u001b[39m=\u001b[39m casts2\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdepartment\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m casts2 \u001b[39m=\u001b[39m casts2\u001b[39m.\u001b[39;49mselectExpr(\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mexplode(department) as department\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mgroupby(\u001b[39m\"\u001b[39;49m\u001b[39mid\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mpivot(\u001b[39m'\u001b[39;49m\u001b[39mdepartment\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mcount()\u001b[39m.\u001b[39mna\u001b[39m.\u001b[39mfill(\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# casts2:  Intermidiate result\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Normalize each column\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/minfei/Documents/SFU/CMPT732/movie-lens-recommender/hh.ipynb#Y132sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m selected_columns \u001b[39m=\u001b[39m [column \u001b[39mfor\u001b[39;00m column \u001b[39min\u001b[39;00m casts2\u001b[39m.\u001b[39mcolumns \u001b[39mif\u001b[39;00m column\u001b[39m!=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m \u001b[39mand\u001b[39;00m column \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m ] \n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/group.py:277\u001b[0m, in \u001b[0;36mGroupedData.pivot\u001b[0;34m(self, pivot_col, values)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[39mPivots a column of the current :class:`DataFrame` and perform the specified aggregation.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39mThere are two versions of pivot function: one that requires the caller to specify the list\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39m[Row(year=2012, Java=20000, dotNET=15000), Row(year=2013, Java=30000, dotNET=48000)]\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[39mif\u001b[39;00m values \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 277\u001b[0m     jgd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jgd\u001b[39m.\u001b[39;49mpivot(pivot_col)\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     jgd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jgd\u001b[39m.\u001b[39mpivot(pivot_col, values)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pyspark/sql/utils.py:196\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    192\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[1;32m    193\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    194\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    195\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <lambda>\n  File \"/var/folders/r_/g7vqnjzj64xb8jpg4qkh9yvr0000gn/T/ipykernel_10181/3485733914.py\", line 3, in <listcomp>\nKeyError: 'known_for_department'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "casts= content.withColumn('cast',\n",
    "                    get_json_object('tmdb_credits', '$.crew')).select('id','cast')\n",
    "casts = casts.filter(casts['cast'].isNotNull()).withColumn('departments', F.udf(lambda x: [i['known_for_department'] for i in json.loads(x)]) ('cast')).select('id', 'departments')\n",
    "casts2= casts.withColumn(\n",
    "    \"department\",\n",
    "    split(regexp_replace(col(\"departments\"), r\"(^\\[)|(\\]$)\", \"\"), \", \")\n",
    ")\n",
    "casts2 = casts2.select('id', 'department')\n",
    "casts2 = casts2.selectExpr(\"id\",\"explode(department) as department\").groupby(\"id\").pivot('department').count().na.fill(0)\n",
    "# casts2:  Intermidiate result\n",
    "# Normalize each column\n",
    "selected_columns = [column for column in casts2.columns if column!='id' and column != '' ] \n",
    "stats = (casts2.groupBy().agg(\n",
    "        *([stddev_pop(x).alias(x + '_stddev') for x in selected_columns] + \n",
    "        [avg(x).alias(x + '_avg') for x in selected_columns])))\n",
    "df2 = casts2.join(broadcast(stats))\n",
    "exprs = ['id']+[((df2[x] - df2[x + '_avg']) / df2[x + '_stddev']).alias(x) for x in selected_columns]\n",
    "df2=df2.select(exprs)\n",
    "#combine multiple columns into one feature:\n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_casts',handleInvalid=\"skip\")\n",
    "df_sep1 = assembler.transform(df2).select('id','sparse_casts').na.fill(value = 0, subset=[\"sparse_casts\"])\n",
    "#convert sparse array to dense array\n",
    "def sparse_to_array(v):\n",
    "        v = DenseVector(v)\n",
    "        new_array = list([float(x) for x in v])\n",
    "        return new_array\n",
    "sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "res = df_sep1.withColumn('cast_composition', sparse_to_array_udf('sparse_casts')).select('id','cast_composition')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #content_tmdb_avg_rating.filter(content_tmdb_avg_rating['cast'].isNull()).show()\n",
    "# content_tmdb_avg_rating= content.withColumn('cast',\n",
    "#                    get_json_object('tmdb_credits', '$.cast')).select('id','cast')\n",
    "# content_tmdb_avg_rating.filter(col('id') ==97216 ).take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "dca39370",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "casts= content.withColumn('cast',\n",
    "                   get_json_object('tmdb_credits', '$.cast')).select('id','cast')\n",
    "casts = casts.filter(casts['cast'].isNotNull()).withColumn('departments', F.udf(lambda x: [i['known_for_department'] for i in json.loads(x)]) ('cast')).select('id', 'departments')\n",
    "casts2= casts.withColumn(\n",
    "    \"department\",\n",
    "    split(regexp_replace(col(\"departments\"), r\"(^\\[)|(\\]$)|(')\", \"\"), \", \")\n",
    ")\n",
    "casts2 = casts2.select('id', 'department')\n",
    "casts2 = casts2.selectExpr(\"id\",\"explode(department) as department\").groupby(\"id\").pivot('department').count().na.fill(0)\n",
    "selected_columns = [column for column in casts2.columns if column!='id' and column != '' ] \n",
    "stats = (casts2.groupBy().agg(\n",
    "        *([stddev_pop(x).alias(x + '_stddev') for x in selected_columns] + \n",
    "          [avg(x).alias(x + '_avg') for x in selected_columns])))\n",
    "df2 = casts2.join(broadcast(stats))\n",
    "exprs = ['id']+[((df2[x] - df2[x + '_avg']) / df2[x + '_stddev']).alias(x) for x in selected_columns]\n",
    "df2=df2.select(exprs)\n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_casts',handleInvalid=\"skip\")\n",
    "df_sep1 = assembler.transform(df2).select('id','sparse_casts').na.fill(value = 0, subset=[\"sparse_casts\"])\n",
    "def sparse_to_array(v):\n",
    "        v = DenseVector(v)\n",
    "        new_array = list([float(x) for x in v])\n",
    "        return new_array\n",
    "sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "res = df_sep1.withColumn('casts', sparse_to_array_udf('sparse_casts')).select('id','casts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c5559d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|               casts|\n",
      "+------+--------------------+\n",
      "| 97216|[2.3061943, -0.01...|\n",
      "| 71936|[1.8627309, -0.01...|\n",
      "| 62526|[0.2789333, -0.01...|\n",
      "|156976|[-0.101178154, -0...|\n",
      "|  5409|[1.6093233, -0.01...|\n",
      "| 32954|[1.3559157, -0.01...|\n",
      "|172267|[-0.35458577, -0....|\n",
      "|152541|[0.78574854, -0.0...|\n",
      "| 89041|[-0.4812896, -0.0...|\n",
      "| 88576|[-0.7346972, -0.0...|\n",
      "|171935|[-0.861401, -0.01...|\n",
      "| 27469|[-0.4812896, -0.0...|\n",
      "|153306|[-0.7346972, -0.0...|\n",
      "|128245|[-0.16453007, -0....|\n",
      "|145301|[-0.101178154, -0...|\n",
      "| 86941|[-0.9247529, -0.0...|\n",
      "|104854|[-0.7980491, -0.0...|\n",
      "|  5556|[1.0391561, -0.01...|\n",
      "|  2509|[-0.16453007, -0....|\n",
      "| 84120|[1.0391561, -0.01...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "01c97f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 287:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|        sparse_casts|\n",
      "+------+--------------------+\n",
      "| 97216|(14,[0,6],[54.0,1...|\n",
      "| 71936|(14,[0,10],[47.0,...|\n",
      "| 62526|     (14,[0],[22.0])|\n",
      "|156976|     (14,[0],[16.0])|\n",
      "|  5409|(14,[0,6,13],[43....|\n",
      "| 32954|(14,[0,7,10,13],[...|\n",
      "|172267|     (14,[0],[12.0])|\n",
      "|152541|     (14,[0],[30.0])|\n",
      "| 89041|(14,[0,11],[10.0,...|\n",
      "| 88576|(14,[0,3],[6.0,1.0])|\n",
      "|171935|      (14,[0],[4.0])|\n",
      "| 27469|     (14,[0],[10.0])|\n",
      "|153306|      (14,[0],[6.0])|\n",
      "|128245|     (14,[0],[15.0])|\n",
      "|145301|     (14,[0],[16.0])|\n",
      "| 86941|      (14,[0],[3.0])|\n",
      "|104854|(14,[0,7],[5.0,1.0])|\n",
      "|  5556|     (14,[0],[34.0])|\n",
      "|  2509|     (14,[0],[15.0])|\n",
      "| 84120|(14,[0,3,4,10,11]...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_casts',handleInvalid=\"skip\")\n",
    "df_sep1 = assembler.transform(casts2).select('id','sparse_casts').na.fill(value = 0, subset=[\"sparse_casts\"])\n",
    "def sparse_to_array(v):\n",
    "        v = DenseVector(v)\n",
    "        new_array = list([float(x) for x in v])\n",
    "        return new_array\n",
    "sparse_to_array_udf = F.udf(sparse_to_array, T.ArrayType(T.FloatType()))\n",
    "res = df_sep1.withColumn('languages', sparse_to_array_udf('sparse_languages')).select('id','languages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0a8266e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 189:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|        sparse_casts|\n",
      "+------+--------------------+\n",
      "|191689|      (15,[1],[1.0])|\n",
      "|147752|      (15,[0],[1.0])|\n",
      "|154984|      (15,[1],[1.0])|\n",
      "|132725|      (15,[1],[1.0])|\n",
      "|174751|      (15,[1],[1.0])|\n",
      "|127419|      (15,[1],[1.0])|\n",
      "|136824|      (15,[0],[1.0])|\n",
      "| 25989|(15,[1,11,14],[1....|\n",
      "|156027|      (15,[1],[1.0])|\n",
      "|160325|      (15,[1],[1.0])|\n",
      "|  2477|      (15,[1],[1.0])|\n",
      "|186437|      (15,[1],[1.0])|\n",
      "| 65986|      (15,[1],[1.0])|\n",
      "|140355|      (15,[1],[1.0])|\n",
      "|109736|      (15,[1],[1.0])|\n",
      "|174903|      (15,[0],[1.0])|\n",
      "|167044|      (15,[1],[1.0])|\n",
      "|105359|(15,[1,11],[1.0,1...|\n",
      "|110759|      (15,[1],[1.0])|\n",
      "|148836|      (15,[0],[1.0])|\n",
      "|142292|(15,[1,11],[1.0,1...|\n",
      "|177479|      (15,[1],[1.0])|\n",
      "|172483|      (15,[1],[1.0])|\n",
      "| 92210|      (15,[1],[1.0])|\n",
      "|177081|      (15,[1],[1.0])|\n",
      "|178473|      (15,[0],[1.0])|\n",
      "|102517|      (15,[1],[1.0])|\n",
      "|184021|      (15,[1],[1.0])|\n",
      "|154360|      (15,[1],[1.0])|\n",
      "| 73492|      (15,[1],[1.0])|\n",
      "|154510|      (15,[1],[1.0])|\n",
      "|123393|(15,[1,8],[1.0,1.0])|\n",
      "|104451|(15,[1,12],[1.0,1...|\n",
      "|170275|      (15,[1],[1.0])|\n",
      "| 93324|      (15,[1],[1.0])|\n",
      "| 68541|      (15,[1],[1.0])|\n",
      "|183757|      (15,[1],[1.0])|\n",
      "|153961|      (15,[1],[1.0])|\n",
      "|114256|      (15,[1],[1.0])|\n",
      "|127040|      (15,[1],[1.0])|\n",
      "|127078|      (15,[1],[1.0])|\n",
      "|109207|(15,[1,8],[1.0,1.0])|\n",
      "|167354|(15,[1,11],[1.0,1...|\n",
      "| 69873|      (15,[1],[1.0])|\n",
      "|140319|      (15,[1],[1.0])|\n",
      "|168998|      (15,[1],[1.0])|\n",
      "|  6387|(15,[1,8,9],[1.0,...|\n",
      "|177903|      (15,[0],[1.0])|\n",
      "|117840|      (15,[1],[1.0])|\n",
      "|101444|      (15,[0],[1.0])|\n",
      "|138300|      (15,[1],[1.0])|\n",
      "|191843|      (15,[1],[1.0])|\n",
      "|164270|      (15,[1],[1.0])|\n",
      "|178637|      (15,[1],[1.0])|\n",
      "|178235|     (15,[14],[1.0])|\n",
      "| 81702|      (15,[1],[1.0])|\n",
      "|141299|(15,[1,11],[1.0,1...|\n",
      "|134603|      (15,[1],[1.0])|\n",
      "|  1188|      (15,[1],[1.0])|\n",
      "|125205|      (15,[1],[1.0])|\n",
      "| 51119|      (15,[1],[1.0])|\n",
      "| 33581|      (15,[1],[1.0])|\n",
      "| 47525|      (15,[1],[1.0])|\n",
      "|146028|(15,[1,8],[1.0,1.0])|\n",
      "|176911|      (15,[1],[1.0])|\n",
      "|   505|(15,[1,14],[1.0,1...|\n",
      "|109953|      (15,[0],[1.0])|\n",
      "|101335|      (15,[0],[1.0])|\n",
      "|156801|      (15,[8],[1.0])|\n",
      "| 61110|      (15,[1],[1.0])|\n",
      "|120274|(15,[1,7],[1.0,1.0])|\n",
      "|127162|      (15,[1],[1.0])|\n",
      "|178845|(15,[1,8,11],[1.0...|\n",
      "| 49007|      (15,[1],[1.0])|\n",
      "|126052|      (15,[0],[1.0])|\n",
      "|  6781|      (15,[1],[1.0])|\n",
      "|179261|      (15,[1],[1.0])|\n",
      "|187335|      (15,[8],[1.0])|\n",
      "|  4905|      (15,[1],[1.0])|\n",
      "|171329|      (15,[1],[1.0])|\n",
      "|159793|(15,[1,11],[1.0,1...|\n",
      "| 71792|(15,[1,4],[1.0,1.0])|\n",
      "|186271|(15,[1,6,11],[1.0...|\n",
      "|115522|(15,[1,11],[1.0,1...|\n",
      "|162978|      (15,[1],[1.0])|\n",
      "|  2752|(15,[1,3,8],[1.0,...|\n",
      "| 45533|(15,[1,4,9,13,14]...|\n",
      "|142823|(15,[1,12],[1.0,1...|\n",
      "|185813|      (15,[1],[1.0])|\n",
      "|184243|(15,[1,8],[1.0,1.0])|\n",
      "| 96700|(15,[1,14],[1.0,1...|\n",
      "|171001|      (15,[1],[1.0])|\n",
      "|110562|      (15,[1],[1.0])|\n",
      "|121300|(15,[1,8],[1.0,1.0])|\n",
      "|116289|(15,[1,12],[1.0,1...|\n",
      "| 27486|      (15,[1],[1.0])|\n",
      "|131726|(15,[1,14],[1.0,1...|\n",
      "|170543|      (15,[1],[1.0])|\n",
      "|  8043|      (15,[1],[1.0])|\n",
      "|179749|(15,[1,8,11],[1.0...|\n",
      "+------+--------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "casts_list = [x[0] for x in casts2.select(explode(\"department\").alias(\"departments\")).distinct().orderBy(\"departments\").collect()]\n",
    "df_sep = casts2.select(\"*\" ,*[\n",
    "        array_contains(\"department\", dep).alias(\"dep_{}\".format(dep)).cast(\"integer\")\n",
    "        for dep in casts_list]\n",
    "    ).drop('department')\n",
    "selected_columns = [column for column in df_sep.columns if column.startswith(\"dep_\")] \n",
    "\n",
    "assembler = VectorAssembler(inputCols=selected_columns, outputCol='sparse_casts',handleInvalid=\"skip\")\n",
    "df_sep1 = assembler.transform(df_sep).select('id','sparse_casts').na.fill(value = 0, subset=[\"sparse_casts\"])\n",
    "df_sep1.show(100)\n",
    "# casts_list = [x[0] for x in casts.select(explode(\"departments\").alias(\"all_departments\")).distinct().orderBy(\"all_departments\").collect()]\n",
    "# casts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "69d236e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dep_',\n",
       " 'dep_Acting',\n",
       " 'dep_Actors',\n",
       " 'dep_Art',\n",
       " 'dep_Camera',\n",
       " 'dep_Costume & Make-Up',\n",
       " 'dep_Creator',\n",
       " 'dep_Crew',\n",
       " 'dep_Directing',\n",
       " 'dep_Editing',\n",
       " 'dep_Lighting',\n",
       " 'dep_Production',\n",
       " 'dep_Sound',\n",
       " 'dep_Visual Effects',\n",
       " 'dep_Writing']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0a8266e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 116:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|    id|         departments|\n",
      "+------+--------------------+\n",
      "|191689|[Acting, Acting, ...|\n",
      "|147752|                  []|\n",
      "|154984|[Acting, Acting, ...|\n",
      "|132725|[Acting, Acting, ...|\n",
      "|174751|[Acting, Acting, ...|\n",
      "|127419|[Acting, Acting, ...|\n",
      "|136824|                  []|\n",
      "| 25989|[Acting, Acting, ...|\n",
      "|156027|[Acting, Acting, ...|\n",
      "|160325|[Acting, Acting, ...|\n",
      "|  2477|[Acting, Acting, ...|\n",
      "|186437|[Acting, Acting, ...|\n",
      "| 65986|[Acting, Acting, ...|\n",
      "|140355|            [Acting]|\n",
      "|109736|[Acting, Acting, ...|\n",
      "|174903|                  []|\n",
      "|167044|            [Acting]|\n",
      "|105359|[Acting, Acting, ...|\n",
      "|110759|[Acting, Acting, ...|\n",
      "|148836|                  []|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "casts= content.withColumn('cast',\n",
    "                   get_json_object('tmdb_credits', '$.cast')).select('id','cast')\n",
    "casts = casts.filter(casts['cast'].isNotNull()).withColumn('departments', F.udf(lambda x: [i['known_for_department'] for i in json.loads(x)]) ('cast')).select('id', 'departments')\n",
    "casts.select(split(col('departments'), ',')).show()\n",
    "# casts_list = [x[0] for x in casts.select(explode(\"departments\").alias(\"all_departments\")).distinct().orderBy(\"all_departments\").collect()]\n",
    "# casts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a763aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('id', LongType(), True), StructField('departments', StringType(), True)])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "casts.schema"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "182dc039c1c6b7e0a24e1f384b69321d9c97647171240a98af3adefbae772270"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
